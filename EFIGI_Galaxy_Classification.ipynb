{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EFIGI_Galaxy_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPEdA0Hb4vOf",
        "colab_type": "text"
      },
      "source": [
        "# Galaxy Calssification using  the EFIGI reference dataset \n",
        "\n",
        "## Author: Avi Vajpeyi, Dr. Rahul Remanan \n",
        "### This project was conceived as part of the 2018 Summer Internship, [@Moad Computer](https://www.moad.computer)\n",
        "\n",
        "### [EFIGI data](https://www.astromatic.net/projects/efigi)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rahulremanan/akash_ganga/blob/master/EFIGI_Galaxy_Classification.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV17Frt2riXQ",
        "colab_type": "text"
      },
      "source": [
        "## Setting notebook behavior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ6dPot4HRTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_raw_data = False #Set True to download the raw data from https://www.astromatic.net/download/efigi/\n",
        "setup = True #Set this flag to True to install all the dependencies and load data from the cloud object storage\n",
        "upload_data = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr-oj4HKEwpW",
        "colab_type": "text"
      },
      "source": [
        "## Copy preprocessed data to Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8zio0_ian14",
        "colab_type": "text"
      },
      "source": [
        "## Connect Google Drive to this session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zzh0e9qjDCJ",
        "colab_type": "text"
      },
      "source": [
        "This code adds ./drive/ (your google drive home folder) to the current session. You cannot cd into this but can access the files on google drive this way.\n",
        "\n",
        "Code obtained from [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2uIr4PHhl2U",
        "colab_type": "code",
        "outputId": "ba0c11e7-4d42-4de1-d167-afda6448824c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "if setup:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh9-Pk3T0tnO",
        "colab_type": "text"
      },
      "source": [
        "### Copy and unzip sorted data from drive to local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILw4g1D2Lkd",
        "colab_type": "text"
      },
      "source": [
        "Data accessible from ./data/train and ./data/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp4EJ2vj1D1Z",
        "colab_type": "code",
        "outputId": "dbaa24bd-9936-4375-e96f-5df16640b7d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "source": [
        "if not download_raw_data and setup:\n",
        "  ! cp /content/gdrive/My\\ Drive/sorted_data_EFIGI.zip ./\n",
        "! mkdir ./drive\n",
        "! mkdir ./drive/EFIGI_Galaxy_Classification/\n",
        "! mkdir ./drive/EFIGI_Galaxy_Classification/output/\n",
        "! mkdir ./drive/EFIGI_Galaxy_Classification/output/checkpoint\n",
        "! cp /content/gdrive/My\\ Drive/Transfer_learn_299_299_EFIGI.h5 ./drive/EFIGI_Galaxy_Classification/output//checkpoint/\n",
        "! mv ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_EFIGI.h5 ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5\n",
        "if setup:\n",
        "  ! unzip -q sorted_data_EFIGI.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./drive’: File exists\n",
            "mkdir: cannot create directory ‘./drive/EFIGI_Galaxy_Classification/’: File exists\n",
            "mkdir: cannot create directory ‘./drive/EFIGI_Galaxy_Classification/output/’: File exists\n",
            "mkdir: cannot create directory ‘./drive/EFIGI_Galaxy_Classification/output/checkpoint’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbUR2n9suuLJ",
        "colab_type": "text"
      },
      "source": [
        "## Define python function to run linux commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOBuQwIbvEE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import subprocess\n",
        " \n",
        "def execute_in_shell(command=None,\n",
        "                     verbose=False):\n",
        "    \"\"\"\n",
        "    This is a function that executes shell scripts from within python.\n",
        "\n",
        "    Example usage:\n",
        "    execute_in_shell(command = ['ls ./some/folder/',\n",
        "                                'ls ./some/folder/  -1 | wc -l'],\n",
        "                     verbose = True )\n",
        "\n",
        "    This command returns dictionary with elements: Output and Error.\n",
        "\n",
        "    Output records the console output,\n",
        "    Error records the console error messages.\n",
        "\n",
        "    :param command: takes a list of shell commands\n",
        "    :param verbose: takes a boolean value to set verbose level\n",
        "    :return: Dictionary with two elements Output and Error\n",
        "    \"\"\"\n",
        "\n",
        "    error = []\n",
        "    output = []\n",
        "\n",
        "    if isinstance(command, list):\n",
        "        for i in range(len(command)):\n",
        "            try:\n",
        "                process = subprocess.Popen(command[i], shell=True,\n",
        "                                           stdout=subprocess.PIPE)\n",
        "                process.wait()\n",
        "                out, err = process.communicate()\n",
        "                error.append(err)\n",
        "                output.append(out)\n",
        "                if verbose:\n",
        "                    print(\n",
        "                        'Success running shell command: {}'.format(command[i]))\n",
        "            except Exception as e:\n",
        "                print('Failed running shell command: {}'.format(command[i]))\n",
        "                if verbose:\n",
        "                    print(type(e))\n",
        "                    print(e.args)\n",
        "                    print(e)\n",
        "\n",
        "    else:\n",
        "        print('The argument command takes a list input ...')\n",
        "    return {'Output': output, 'Error': error}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq8A4j1B5S59",
        "colab_type": "text"
      },
      "source": [
        "## Download and sort data\n",
        "Currently only using coloured processed images rather than the sperate images that the final image is composed of. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cu1tAhVhQS",
        "colab_type": "text"
      },
      "source": [
        "### Download data\n",
        "The EFIGI dataset info we are using is in 6 separate compressed archives (gzipped\n",
        "tar format):\n",
        "- efigi_tables-1.6.tgz: 6 ASCII tables, including morphological information\n",
        "- efigi_png_gri-1.6.tgz: 4458 PNG images in the SDSS g,r and i bands\n",
        "- efigi_ima_u-1.6.tgz: 4458 galaxy images in the SDSS u-band (FITS format)\n",
        "- efigi_ima_g-1.6.tgz: 4458 galaxy images in the SDSS g-band (FITS format)\n",
        "- efigi_ima_r-1.6.tgz: 4458 galaxy images in the SDSS r-band (FITS format)\n",
        "- efigi_ima_i-1.6.tgz: 4458 galaxy images in the SDSS i-band (FITS format)\n",
        "- efigi_ima_z-1.6.tgz: 4458 galaxy images in the SDSS z-band (FITS format)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Q_47OX5aeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if download_raw_data:\n",
        "  ! mkdir ./data\n",
        "  ! mkdir ./data/raw\n",
        "\n",
        " \n",
        "  ! wget  -O ./data/raw/efigi-1.6.tgz \"https://www.astromatic.net/download/efigi/efigi_tables-1.6.2.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_png_gri-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_u_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_u-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_g_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_g-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_r_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_r-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_i_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_i-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_z_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_z-1.6.tgz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncwhv7gGx-7P",
        "colab_type": "text"
      },
      "source": [
        "### Zip and move raw files to the object drive\n",
        "DO ONLY ONCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgdwwES6xwIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if upload_data:\n",
        "  ! zip -q -r raw_data_EFIGI.zip ./data/raw/\n",
        "  ! cp raw_data_EFIGI.zip /content/gdrive//My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9qyTgep-nXS",
        "colab_type": "text"
      },
      "source": [
        "### Unpack data from tgz\n",
        "Data stored in\n",
        "\n",
        "* Tables:  ` ./data/raw/efigi-1.6/ `\n",
        "* Colored Images:   ` ./data/raw/efigi-1.6/png ` \n",
        "* FITS: `/efigi-1.6/ima_g,  ima_i, ima_u, ima_z`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDtOzw_Lv-Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if download_raw_data:\n",
        "  import glob\n",
        "  tgz_files = glob.glob(\"./data/raw/*tgz\")\n",
        "  for tgz_file in tgz_files:\n",
        "    command=[\"tar xzf \"+tgz_file+\" -C ./data/raw/\", \"rm \"+tgz_file]\n",
        "    execute_in_shell(command, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LqW2qQLUjnO",
        "colab_type": "text"
      },
      "source": [
        "### Convert fits to png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z5Hha_mS3_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.utils.data import get_pkg_data_filename\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def fits_to_png(fits_fn):\n",
        "    # Generally the image information is located in the Primary HDU (ext 0)\n",
        "    # read the image data from this first extension using the keyword argument\n",
        "    data = fits.getdata(fits_fn, ext=0)\n",
        "\n",
        "    sizes = np.shape(data)\n",
        "    height = float(sizes[0])\n",
        "    width = float(sizes[1])\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches(width / height, 1, forward=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "\n",
        "    ax.imshow(data, cmap=\"binary\")\n",
        "\n",
        "    # createing png filename from fits filename\n",
        "    png_fn = fits_fn.split(\".fits\")[0] + \".png\"\n",
        "\n",
        "\n",
        "    plt.savefig(png_fn, dpi=height)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def fits_folder_to_png(dir, verbose):\n",
        "\n",
        "    fits_files = glob.glob( dir+\"*.fits\")\n",
        "    num_files = len(fits_files)\n",
        "    status_flag = num_files * 0.1\n",
        "\n",
        "    for i in range(0, num_files):\n",
        "        fits_to_png(fits_files[i])\n",
        "\n",
        "        if verbose and i > status_flag:\n",
        "            status_flag += num_files * 0.1\n",
        "            p_done = (i * 100// num_files) \n",
        "            print(str(p_done)+\"% processed\")\n",
        "\n",
        "def delete_fits_from_folder(dir):\n",
        "    fits_files = glob.glob(dir+\"*.fits\")\n",
        "    for f in fits_files:\n",
        "      os.remove(f)\n",
        "\n",
        "\n",
        "def make_movie_from_png(video_name, dir):\n",
        "\n",
        "    images = glob.glob(dir + \"*.png\")\n",
        "    frame = cv2.imread(images[0])\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    video = cv2.VideoWriter(video_name, -1, 25, (width, height))\n",
        "\n",
        "    for image in images:\n",
        "        video.write(cv2.imread(image))\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkULVfzMzna",
        "colab_type": "text"
      },
      "source": [
        "Execute following to convert the images into pngs.\n",
        "This can take a while...Can be timed out and if you are then run again, itll pick up where it left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK3zMZlc0JmL",
        "colab_type": "code",
        "outputId": "60b594a4-fdee-4229-c4df-0b969393ab76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import gc\n",
        "\n",
        "if setup:\n",
        "  FITS_folders = [\"ima_g\", \"ima_i\",\"ima_u\",\"ima_z\",\"ima_r\"]\n",
        "  for fits_folder in FITS_folders:\n",
        "    dir = \"./data/raw/efigi-1.6/\"+fits_folder+\"/\"\n",
        "    print(\"Processing \"+dir)\n",
        "    fits_folder_to_png(dir, verbose=True)\n",
        "    delete_fits_from_folder(dir)\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing ./data/raw/efigi-1.6/ima_g/\n",
            "Processing ./data/raw/efigi-1.6/ima_i/\n",
            "Processing ./data/raw/efigi-1.6/ima_u/\n",
            "Processing ./data/raw/efigi-1.6/ima_z/\n",
            "Processing ./data/raw/efigi-1.6/ima_r/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRDdIwgRMrjG",
        "colab_type": "text"
      },
      "source": [
        "### Make Galaxy Type Enum "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u3oX1sOMqyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum, auto, unique\n",
        "@unique\n",
        "class T(Enum):\n",
        "  ''' Enum to store the different types of galaxies\n",
        "  '''\n",
        "  ELLIPTICAL = auto()\n",
        "  LENTICULAR = auto()\n",
        "  SPIRAL = auto()\n",
        "  IRREGULAR = auto()\n",
        "  DWARF = auto()\n",
        "\n",
        "  def __str__(self):\n",
        "    '''To print the name of the galaxy type when enum printed\n",
        "    '''\n",
        "    return str(self.name)\n",
        "\n",
        "def check_class(t_val):\n",
        "  '''Takes the t_val attribute and returns the associated enum\n",
        "  '''\n",
        "  try:\n",
        "    t_val = int(t_val)\n",
        "  except ValueError:\n",
        "    pass  # it was a string, not an int.\n",
        "  if t_val < -3:\n",
        "    return T.ELLIPTICAL\n",
        "  elif  t_val < 0:\n",
        "    return T.LENTICULAR\n",
        "  elif t_val < 10:\n",
        "    return T.SPIRAL\n",
        "  elif t_val == 10:\n",
        "    return T.IRREGULAR\n",
        "  elif t_val == 11:\n",
        "    return T.DWARF\n",
        "  else:\n",
        "    print (\"ERROR\")\n",
        "    # raise exception\n",
        "    return null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvCeZeuWG61a",
        "colab_type": "text"
      },
      "source": [
        "### Make Organisational Folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3DXbGaCG6Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "train_dir = './data/train/'\n",
        "val_dir = './data/validation'\n",
        "if setup and download_raw_data:\n",
        "  galaxy_classes = [name for name, gal_type in T.__members__.items()]\n",
        "  execute_in_shell([\"mkdir {} {}\".format(train_dir, val_dir)])\n",
        "  for galaxy_class in galaxy_classes:\n",
        "    commands =[\"mkdir {}{} {}{}\"\n",
        "               .format(train_dir, \n",
        "                       galaxy_class, \n",
        "                       val_dir, \n",
        "                       galaxy_class)]\n",
        "    execute_in_shell(commands)\n",
        "\n",
        "  print(\"Folders in {}: \".format(train_dir))\n",
        "  print (os.listdir(train_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w54wmJq1B9b4",
        "colab_type": "text"
      },
      "source": [
        "### Move files from orignal folder to their classes folder\n",
        "\n",
        "The table `data/raw/efigi-1.6/EFIGI_attributes.txt` has several attributes. We need the \"PGC_name\" and \"T\" (the file name and EFIGI morphological type). Based on this, we will move the file from `./raw` to `./train/{type}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsTTBmN9DtjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "def row_generator(filepath):\n",
        "  ''' Grabs one row of the txt file if its not a comment\n",
        "  '''\n",
        "  with open(filepath) as fp:\n",
        "\n",
        "      # Skip initial comments that starts with #\n",
        "      while True:\n",
        "          row = fp.readline()\n",
        "          if not row.startswith('#'):\n",
        "              break\n",
        "\n",
        "      # Second while loop to process the rest of the file\n",
        "      while row:\n",
        "          yield (row)\n",
        "          row = fp.readline()\n",
        "\n",
        "\n",
        "\n",
        "def move_file_by_class(filename, type, image_foldername):\n",
        "  current_dir = \"data/raw/efigi-1.6/\"+image_foldername+\"/\"+filename\n",
        "  destination_dir = \"data/train/\"+ type.name + \"/\" + filename\n",
        "  shutil.move(current_dir, destination_dir)\n",
        "\n",
        "\n",
        "def move_files_according_to_txt(txt_filepath, img_folder, extension, verbose):\n",
        "  print(\"Moving files from \"+img_folder)\n",
        "\n",
        "  count = 0\n",
        "  for line in row_generator(txt_filepath):\n",
        "    attributes = line.split()\n",
        "\n",
        "    # create file name based on PGC_name\n",
        "    if extension is None:\n",
        "      image_file_name = attributes[0]+\".png\"\n",
        "    else:\n",
        "      image_file_name = attributes[0]+\"_\"+extension+\".png\"\n",
        "\n",
        "    # get type according to dataset\n",
        "    image_class = check_class(attributes[1])\n",
        "\n",
        "\n",
        "    move_file_by_class(image_file_name, image_class, img_folder)\n",
        "\n",
        "    count +=1\n",
        "    if count % 100 == 0 and verbose:\n",
        "      print (\"Image Num\"+str(count)+\": \" +image_file_name+ \" is a \" + image_class.name)\n",
        "  print(\"Done moving from \"+img_folder+ \" to data/train/\")\n",
        "\n",
        "\n",
        "\n",
        "if setup and download_raw_data:\n",
        "  image_folders = [\"png\",\"ima_g\", \"ima_i\", \"ima_u\", \"ima_z\", \"ima_r\"]\n",
        "  extensions =[None, \"g\",\"i\",\"u\",\"z\",\"r\"]\n",
        "\n",
        "  for i in range(0,len(extensions)):\n",
        "    move_files_according_to_txt(txt_filepath = \"data/raw/efigi-1.6/EFIGI_attributes.txt\",\n",
        "                                img_folder = image_folders[i], \n",
        "                                extension = extensions[i], \n",
        "                                verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-A9_M1QcoeW",
        "colab_type": "text"
      },
      "source": [
        "### Shuffle some files from training folder to validation folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWKfOmBkCbXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob, random \n",
        "if setup and download_raw_data: \n",
        "  subfolders = [f.path for f in os.scandir(train_dir) if f.is_dir()] \n",
        "\n",
        "  # For each training folder \n",
        "  for train_class_dir in subfolders:\n",
        "\n",
        "    # Get total number of files in folder\n",
        "    images = glob.glob(train_class_dir+\"/*.png\")\n",
        "    total_num = len(images)\n",
        "    print (train_class_dir +\" has \" + str(total_num)+\" images.\")\n",
        "\n",
        "    # Shuffle 20% files\n",
        "    number_of_validation = int(0.2*float(total_num)) # 20% validation\n",
        "    files_to_move = random.sample(images, number_of_validation)\n",
        "\n",
        "\n",
        "    class_name = train_class_dir.split(\"/\")[-1]\n",
        "\n",
        "    # Move 20% to the validation folder of the same class\n",
        "    for file_dir in files_to_move:\n",
        "      destination_dir = file_dir.split(\"/train/\")[0]+\"/validation/\"+file_dir.split(\"/train/\")[-1]\n",
        "      shutil.move(file_dir, destination_dir)\n",
        "\n",
        "    num_images_remaining = len(glob.glob(train_class_dir+\"/*.png\"))\n",
        "    print (\"After transfer \" + str(num_images_remaining)+\" images will remain as training data.\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lszJVNpPf4_",
        "colab_type": "text"
      },
      "source": [
        "### Remove Raw Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti0g17tmPfcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "if setup and download_raw_data:\n",
        "  shutil.rmtree(\"./data/raw\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDIdQ8BQQQGo",
        "colab_type": "text"
      },
      "source": [
        "### Zip and move sorted data to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw9p0aUSQXmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if upload_data:\n",
        "  ! zip -q -r sorted_data_EFIGI.zip ./data\n",
        "  ! cp -v sorted_data_EFIGI.zip /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFLTKb79r4AU",
        "colab_type": "text"
      },
      "source": [
        "## Train a deep convolutional neural network calssifier\n",
        "\n",
        "- Galaxy classifier using Inception-ResNet version 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfKo3b02shb",
        "colab_type": "text"
      },
      "source": [
        "### Imports for ML that will be needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJU5Dfq1uYh3",
        "colab_type": "code",
        "outputId": "11e3c4af-76b4-4117-d7c4-f939e88ab1fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "try:\n",
        "    import h5py\n",
        "except:\n",
        "    print ('Package h5py needed for saving model weights ...')\n",
        "    sys.exit(1)\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import tensorflow\n",
        "    import keras\n",
        "except:\n",
        "    print ('This code uses tensorflow deep-learning framework and keras api ...')\n",
        "    print ('Install tensorflow and keras to train the classifier ...')\n",
        "    sys.exit(1)\n",
        "    \n",
        "import PIL # Python Imaging Library\n",
        "from collections import defaultdict\n",
        "from keras.applications.inception_v3 import InceptionV3,    \\\n",
        "                                            preprocess_input as preprocess_input_inceptionv3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2,    \\\n",
        "                                            preprocess_input as preprocess_input_inceptionv4\n",
        "from keras.models import Model,                             \\\n",
        "                         model_from_json,                    \\\n",
        "                         load_model\n",
        "from keras.layers import Conv2D,                            \\\n",
        "                         Dense,                             \\\n",
        "                         GlobalAveragePooling2D,            \\\n",
        "                         Dropout,                           \\\n",
        "                         BatchNormalization,\\\n",
        "                         Concatenate\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,                           \\\n",
        "                             RMSprop,                       \\\n",
        "                             Adagrad\n",
        "from keras.callbacks import EarlyStopping,   \\\n",
        "                            ModelCheckpoint, \\\n",
        "                            ReduceLROnPlateau\n",
        "from keras.regularizers import l2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB6UlsJ0m30a",
        "colab_type": "text"
      },
      "source": [
        "### Fetch saved weights from Google drive storage object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4IvMMYis0kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "try:\n",
        "    import h5py\n",
        "except:\n",
        "    print('Package h5py needed for saving model weights ...')\n",
        "    sys.exit(1)\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import tensorflow\n",
        "    import keras\n",
        "except:\n",
        "    print(\n",
        "        'This code uses tensorflow deep-learning framework and keras api ...')\n",
        "    print('Install tensorflow and keras to train the classifier ...')\n",
        "    sys.exit(1)\n",
        "\n",
        "import PIL  # Python Imaging Library\n",
        "from collections import defaultdict\n",
        "from keras.applications.inception_v3 import InceptionV3, \\\n",
        "    preprocess_input as preprocess_input_inceptionv3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, \\\n",
        "    preprocess_input as preprocess_input_inceptionv4\n",
        "from keras.models import Model, \\\n",
        "    model_from_json, \\\n",
        "    load_model\n",
        "from keras.layers import Dense, \\\n",
        "    GlobalAveragePooling2D, \\\n",
        "    Dropout, \\\n",
        "    BatchNormalization,\\\n",
        "    merge, multiply, Lambda\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, \\\n",
        "    RMSprop, \\\n",
        "    Adagrad\n",
        "from keras.callbacks import EarlyStopping, \\\n",
        "    ModelCheckpoint, \\\n",
        "    ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def generate_timestamp():\n",
        "    \"\"\"\n",
        "    Generates a timestring in the format year_month_day-hr_min_sec\n",
        "\n",
        "    :return: a string that holds the timestring\n",
        "    \"\"\"\n",
        "    timestring = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "    print(\"Time stamp generated: \" + timestring)\n",
        "    return timestring\n",
        "\n",
        "\n",
        "def is_valid_file(parser, arg):\n",
        "    \"\"\"\n",
        "    Checks if a file passed as an arg exists\n",
        "\n",
        "    :param parser:  an ArgumentParser object that can process command line args\n",
        "    :param arg: filename\n",
        "    :return: the filename if the file exists, otherwise null\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(arg):\n",
        "        parser.error(\"The file %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def is_valid_dir(parser, arg):\n",
        "    \"\"\"\n",
        "    Checks if a dir passed as an arg exists\n",
        "\n",
        "    :param parser: an ArgumentParser object that can process command line args\n",
        "    :param arg: directory path\n",
        "    :return: the dir path if the dir exists\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(arg):\n",
        "        parser.error(\"The folder %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def string_to_bool(val):\n",
        "    \"\"\"\n",
        "    Converts yes, y, 1, t, n, 0, f, False into their appropriate bools\n",
        "\n",
        "    :param val: a string\n",
        "    :return: the associated bool (True/False) otherwise an error\n",
        "    \"\"\"\n",
        "    if val.lower() in ('yes', 'true', 't', 'y', '1', 'yeah'):\n",
        "        return True\n",
        "    elif val.lower() in ('no', 'false', 'f', 'n', '0', 'none'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected ...')\n",
        "\n",
        "\n",
        "def get_nb_files(directory):\n",
        "    \"\"\"\n",
        "    Gets the number of files in a directory\n",
        "\n",
        "    :param directory: the dir that we are counting the number of files in\n",
        "    :return: the count of the files in the dir (0 if the dir doesnt exist)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    cnt = 0\n",
        "    for r, dirs, files in os.walk(directory):\n",
        "        for dr in dirs:\n",
        "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
        "    return cnt\n",
        "\n",
        "\n",
        "def setup_to_transfer_learn(model, base_model, optimizer):\n",
        "    \"\"\"\n",
        "    Helps join a previous model (the base model) to new model\n",
        "\n",
        "    ???: where are base_model and model joined\n",
        "\n",
        "    :param model: the new model to be trained\n",
        "    :param base_model: the pre existing base model, already trained\n",
        "    :param optimizer: the optimizer function to train the new model\n",
        "    :return: the new model\n",
        "    \"\"\"\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_k2ye7FDJBJC",
        "colab_type": "text"
      },
      "source": [
        "## [Attention augmented convolutional networks](https://arxiv.org/pdf/1904.09925.pdf) and a dense soft-attention layer\n",
        "\n",
        "The implementation of dense attention layer is a modified fork described [here](https://github.com/philipperemy/keras-attention-mechanism/blob/master/attention_dense.py).\n",
        "\n",
        "The implementation of the attention convolutional network using keras is a modifier fork, described [here](https://github.com/titu1994/keras-attention-augmented-convs/blob/master/attn_augconv.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwfCZaBrJAVq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_top_layer(args, base_model, nb_classes):\n",
        "  \"\"\"\n",
        "    This functions adds a fully connected convolutional neural network layer to a base model.\n",
        "    \n",
        "    The required input arguments for this function are: args, base_model and nb_classes.\n",
        "        args: argument inputs the user arguments to be passed to the function,\n",
        "        base_model: argument inputs the base model architecture to be added to the top layer,\n",
        "        nb_classes: argument inputs the total number of classes for the output layer.    \n",
        "  \"\"\"\n",
        "  try:\n",
        "      dropout = float(args.dropout[0])\n",
        "      weight_decay = float(args.decay[0])\n",
        "      enable_dropout = args.enable_dropout[0]\n",
        "  except:\n",
        "      dropout = DEFAULT_DROPOUT\n",
        "      weight_decay = 0.01\n",
        "      enable_dropout = True\n",
        "      print ('Invalid user input ...')\n",
        "      \n",
        "  try:\n",
        "      activation = str(args.activation[0]).lower()\n",
        "      print ('Building model using activation function: ' + str(activation))\n",
        "  except:\n",
        "      activation = 'relu'\n",
        "      print ('Invalid user input for activation function ...')\n",
        "      print ('Choice of activation functions: hard_sigmoid, elu, linear, relu, selu, sigmoid, softmax, softplus, sofsign, tanh ...')\n",
        "      print ('Building model using default activation function: relu')\n",
        "      \n",
        "  base_model.trainable = False\n",
        "  bm = base_model.output\n",
        "  \n",
        "  x = Dropout(dropout,\n",
        "              name='gloablDropout')(bm,\n",
        "                                      training=enable_dropout)\n",
        "  gap = GlobalAveragePooling2D(name='gloablAveragePooling2D')(x)\n",
        "  bn = BatchNormalization(name='gloabl_batchNormalization')(x)\n",
        "  \n",
        "  enable_attention = True\n",
        "  enable_multilayerDense = False\n",
        "  ATTN_UNIT_SIZE = 256\n",
        "  ATTN_CONV_LAYER_DEPTH = 4\n",
        "  \n",
        "  if enable_attention:\n",
        "    \"\"\"\n",
        "    Covolutional attention layers \n",
        "    \"\"\"\n",
        "    preTrained_featureSize = base_model.get_output_shape_at(0)[-1]\n",
        "    x = bn\n",
        "    for i in range(ATTN_CONV_LAYER_DEPTH):\n",
        "        x = Conv2D(ATTN_UNIT_SIZE, \n",
        "                   kernel_size=(1,1),\n",
        "                   padding='same',\n",
        "                   activation=activation,\n",
        "                   name='convAttentionLayer_{}'.format(i))(x)\n",
        "        x = Dropout(dropout,\n",
        "                    name='attentionDropout_{}'.format(i))(x,\n",
        "                                               training=enable_dropout)\n",
        "    \n",
        "    \n",
        "    x = Conv2D(1, \n",
        "               kernel_size=(1,1),\n",
        "               padding='valid',\n",
        "               activation=activation,\n",
        "               name='convAttentionLayer_1D')(x)\n",
        "    x = Dropout(dropout,\n",
        "                name='attentionDropout_1D')(x,\n",
        "                                           training=enable_dropout)\n",
        "    \n",
        "    upConv2d_weights = np.ones((1, 1, 1, 1, preTrained_featureSize))\n",
        "    \n",
        "    upConv2d = Conv2D(preTrained_featureSize,\n",
        "                      kernel_size = (1,1), \n",
        "                      padding = 'same', \n",
        "                      activation = 'linear', \n",
        "                      use_bias = False, \n",
        "                      weights = upConv2d_weights,\n",
        "                      name='upConv2d')\n",
        "    upConv2d.trainable = False\n",
        "    \n",
        "    x = upConv2d(x)\n",
        "    maskFeatures = multiply([x,\n",
        "                             bn],\n",
        "                            name='multiply_maskFeature')\n",
        "    \n",
        "    gapFeatures = GlobalAveragePooling2D(name='attentionGlobalAveragePooling_features')(maskFeatures)\n",
        "    gapMask = GlobalAveragePooling2D(name='attentionGlobalAveragePooling_mask')(x)\n",
        "  \n",
        "    gap = Lambda(lambda x: x[0]/x[1], \n",
        "                 name = 'rescaleGlobalAeragePooling')([gapFeatures,\n",
        "                                                       gapMask])\n",
        "  if enable_multilayerDense:\n",
        "    x = Dropout(dropout,\n",
        "                name='dropout_fc1')(gap,\n",
        "                                    training=enable_dropout)\n",
        "    x = BatchNormalization(name='batchNormalization_fc1')(x)\n",
        "    x = Dense(FC_SIZE, \n",
        "              activation=activation,\n",
        "              kernel_regularizer=l2(weight_decay),\n",
        "              name='dense_fc1')(x)\n",
        "    x = Dropout(dropout,\n",
        "                name='dropout_fc2')(x,\n",
        "                                    training=enable_dropout)\n",
        "  \n",
        "    x1 = Dense(FC_SIZE, \n",
        "               activation=activation,\n",
        "               kernel_regularizer=l2(weight_decay),\n",
        "               name=\"dense_fc2\")(x)\n",
        "    x1 = Dropout(dropout,\n",
        "                 name = 'dropout_fc3')(x1, \n",
        "                                       training=enable_dropout)\n",
        "    x1 = BatchNormalization(name=\"batchNormalization_fc2\")(x1)\n",
        "    x1 = Dense(FC_SIZE, \n",
        "               activation=activation, \n",
        "               kernel_regularizer=l2(weight_decay),\n",
        "               name=\"dense_fc3\")(x1)\n",
        "    x1 = Dropout(dropout,\n",
        "                 name = 'dropout_fc4')(x1, \n",
        "                                  training=enable_dropout)\n",
        "\n",
        "    x2 = Dense(FC_SIZE, \n",
        "               activation=activation, \n",
        "               kernel_regularizer=l2(weight_decay),\n",
        "               name=\"dense_fc4\")(x)\n",
        "    x2 = Dropout(dropout,\n",
        "                 name = 'dropout_fc5')(x2, \n",
        "                                  training=enable_dropout)\n",
        "    x2 = BatchNormalization(name=\"batchNormalization_fc3\")(x2)\n",
        "    x2 = Dense(FC_SIZE, \n",
        "               activation=activation, \n",
        "               kernel_regularizer=l2(weight_decay),\n",
        "               name=\"dense_fc5\")(x2)\n",
        "    x2 = Dropout(dropout,\n",
        "                 name = 'dropout_fc6')(x2, \n",
        "                                       training=enable_dropout)\n",
        "\n",
        "    x12 = concatenate([x1, x2], name = 'mixed11')\n",
        "    x12 = Dropout(dropout,\n",
        "                  name = 'dropout_fc7')(x12, \n",
        "                                        training=enable_dropout)\n",
        "    x12 = Dense(FC_SIZE//16, \n",
        "                activation=activation, \n",
        "                kernel_regularizer=l2(weight_decay),\n",
        "                name = 'dense_fc6')(x12)\n",
        "    x12 = Dropout(dropout,\n",
        "                  name = 'dropout_fc8')(x12, \n",
        "                                        training=enable_dropout)\n",
        "    x12 = BatchNormalization(name=\"batchNormalization_fc4\")(x12)\n",
        "    x12 = Dense(FC_SIZE//32, \n",
        "                activation=activation, \n",
        "                kernel_regularizer=l2(weight_decay),\n",
        "                name = 'dense_fc7')(x12)\n",
        "    x12 = Dropout(dropout,\n",
        "                  name = 'dropout_fc9')(x12, \n",
        "                                         training=enable_dropout)\n",
        "  \n",
        "    x3 = Dense(FC_SIZE//2, \n",
        "               activation=activation, \n",
        "               kernel_regularizer=l2(weight_decay),\n",
        "               name = 'dense_fc8')(gap)\n",
        "    x3 = Dropout(dropout,\n",
        "                 name = 'dropout_fc11')(x3, \n",
        "                                  training=enable_dropout)\n",
        "    x3 = BatchNormalization(name=\"batchNormalization_fc5\")(x3)\n",
        "    x3 = Dense(FC_SIZE//2, \n",
        "               activation=activation, \n",
        "               kernel_regularizer=l2(weight_decay),\n",
        "               name = 'dense_fc9')(x3)\n",
        "    x3 = Dropout(dropout,\n",
        "                 name = 'dropout_fc12')(x3, \n",
        "                                        training=enable_dropout)\n",
        "  \n",
        "    xout = concatenate([x12, x3], name ='mixed12')\n",
        "    xout = Dense(FC_SIZE//32, \n",
        "                 activation= activation, \n",
        "                 kernel_regularizer=l2(weight_decay),\n",
        "                 name = 'dense_fc10')(xout)\n",
        "    xout = Dropout(dropout,\n",
        "                   name = 'dropout_fc13')(xout, \n",
        "                                     training=enable_dropout)\n",
        "    \n",
        "  else:\n",
        "    x = BatchNormalization(name='batchNormalization_fc1')(gap)\n",
        "    xout = Dense(FC_SIZE, \n",
        "                 activation=activation,\n",
        "                 kernel_regularizer=l2(weight_decay),\n",
        "                 name='dense_fc1')(x)\n",
        "    xout = Dropout(dropout,\n",
        "                   name = 'dropout_fc13')(xout, \n",
        "                                          training=enable_dropout)\n",
        "    \n",
        "  predictions = Dense(nb_classes,           \\\n",
        "                      activation='softmax', \\\n",
        "                      kernel_regularizer=l2(weight_decay),\n",
        "                      name='prediction')(xout) # Softmax output layer\n",
        "  model = Model(inputs=base_model.input, \n",
        "                outputs=predictions)\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pX4lgzZx1TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_to_finetune(model, optimizer, NB_FROZEN_LAYERS):\n",
        "    \"\"\"\n",
        "    Freezes some of the bottom layers of the model to not be trained\n",
        "\n",
        "    :param model: the current ML model\n",
        "    :param optimizer: optimizer function being used for the training of the model\n",
        "    :param NB_FROZEN_LAYERS: Freeze the bottom NB_LAYERS and retrain the remaining top layers\n",
        "    :return: the updated new model with some of the bottom layers frozen\n",
        "    \"\"\"\n",
        "    for layer in model.layers[:NB_FROZEN_LAYERS]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[NB_FROZEN_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MARehmzbx6th",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(args, name, model):\n",
        "    \"\"\"\n",
        "    Saves the\n",
        "    1) model weights in name.model\n",
        "    2) model config (the number of layers, activation funcs, etc) in name.json.\n",
        "    Both are stored in a dir specified in args.output_dir[0].\n",
        "\n",
        "    :param args: holds the saving dir in args.output_dir[0]\n",
        "    :param name: name of the saved model weights and model config\n",
        "    :param model: the model to be saved\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "    file_loc = args.output_dir[0]\n",
        "    file_pointer_str = file_loc + \"//trained_\" + timestr\n",
        "    file_pointer = os.path.join(file_pointer_str)\n",
        "    model_save_str = file_pointer + \"_weights\" + str(name) + \".model\"\n",
        "    model.save_weights(os.path.join(model_save_str))\n",
        "\n",
        "    model_json = model.to_json()  # Serialize model to JSON\n",
        "    config_save_str = file_pointer + \"_config\" + str(name) + \".json\"\n",
        "    with open(os.path.join(config_save_str), \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    print(\"Saved the trained model weights to: \" +\n",
        "          str(os.path.join(file_pointer + \"_weights\" + str(name) + \".model\")))\n",
        "    print(\"Saved the trained model configuration as a json file to: \" +\n",
        "          str(os.path.join(file_pointer + \"_config\" + str(name) + \".json\")))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDvlzlceB-x7",
        "colab_type": "code",
        "outputId": "a4273df8-f0aa-4675-c653-567bfe568ada",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def generate_labels(args):\n",
        "    \"\"\"\n",
        "    Generates labels from folder names in data/train/ and data/validation/\n",
        "    IF the labels from train and validation folders match, labels are returned\n",
        "    and a json with the lables is saved\n",
        "\n",
        "    :param args: holds the saving dir in args.output_dir[0]\n",
        "    :return: a sorted dict with the labels\n",
        "    \"\"\"\n",
        "    file_loc = args.output_dir[0]\n",
        "    file_pointer = os.path.join(file_loc + \"//trained_labels\")\n",
        "\n",
        "    data_dir = args.train_dir[0]\n",
        "    val_dir_ = args.val_dir[0]\n",
        "\n",
        "    dt = defaultdict(list)\n",
        "    dv = defaultdict(list)\n",
        "\n",
        "    for root, subdirs, files in os.walk(data_dir):\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(root, filename)\n",
        "            assert file_path.startswith(data_dir)\n",
        "            suffix = file_path[len(data_dir):]\n",
        "            suffix = suffix.lstrip(\"/\")\n",
        "            label = suffix.split(\"/\")[0]\n",
        "            dt[label].append(file_path)\n",
        "\n",
        "    for root, subdirs, files in os.walk(val_dir_):\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(root, filename)\n",
        "            assert file_path.startswith(val_dir_)\n",
        "            suffix = file_path[len(val_dir_):]\n",
        "            suffix = suffix.lstrip(\"/\")\n",
        "            label = suffix.split(\"/\")[0]\n",
        "            dv[label].append(file_path)\n",
        "\n",
        "    labels = sorted(dt.keys())\n",
        "    val_labels = sorted(dv.keys())\n",
        "\n",
        "    if set(labels) == set(val_labels):\n",
        "        print(\"Training labels: \" + str(labels))\n",
        "        print(\"Validation labels: \" + str(val_labels))\n",
        "        with open(os.path.join(file_pointer + \".json\"), \"w\") as json_file:\n",
        "            json.dump(labels, json_file)\n",
        "    else:\n",
        "        print(\"Training labels: \" + str(labels))\n",
        "        print(\"Validation labels: \" + str(val_labels))\n",
        "        print(\"Mismatched training and validation data labels ...\")\n",
        "        print(\n",
        "            \"Sub-folder names do not match between training and validation \"\n",
        "            \"directories ...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def generate_plot(args, name, model_train):\n",
        "    \"\"\"\n",
        "    Checks if plots were made and if so, displays plots of training\n",
        "\n",
        "    :param args: holds the bool about if there were to be plots of\n",
        "    training made, in args.plot[0]\n",
        "    :param name: name of plots\n",
        "    :param model_train: the model that was trained\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "    gen_plot = args.plot[0]\n",
        "    if gen_plot == True:\n",
        "        plot_training(args, name, model_train)\n",
        "    else:\n",
        "        print(\"No training summary plots generated ...\")\n",
        "        print(\"Set: --plot True for creating training summary plots\")\n",
        "\n",
        "\n",
        "def plot_training(args, name, history):\n",
        "    \"\"\"\n",
        "    Plots the accuracy vs epoch and loss vs epoch and saves as png files\n",
        "\n",
        "    ???: actual parameter is \"model\" but formal parameter is \"history\"...\n",
        "\n",
        "    :param args: holds the outpt dir\n",
        "    :param name: the names of the plots\n",
        "    :param history: the datapoints of the training\n",
        "    :return: null\n",
        "    \"\"\"\n",
        "    output_loc = args.output_dir[0]\n",
        "\n",
        "    output_file_acc = os.path.join(output_loc +\n",
        "                                   \"//training_plot_acc_\" +\n",
        "                                   timestr + str(name) + \".png\")\n",
        "    output_file_loss = os.path.join(output_loc +\n",
        "                                    \"//training_plot_loss_\" +\n",
        "                                    timestr + str(name) + \".png\")\n",
        "    fig_acc = plt.figure()\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    fig_acc.savefig(output_file_acc, dpi=fig_acc.dpi)\n",
        "    print(\"Successfully created the training accuracy plot: \"\n",
        "          + str(output_file_acc))\n",
        "    plt.close()\n",
        "\n",
        "    fig_loss = plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    fig_loss.savefig(output_file_loss, dpi=fig_loss.dpi)\n",
        "    print(\"Successfully created the loss function plot: \"\n",
        "          + str(output_file_loss))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    \"\"\"\n",
        "    Helper function to train a model based on args\n",
        "\n",
        "    :param args: some of the arguments and possible values are\n",
        "            args.config_file = ['./model/model_efc.json']\n",
        "            args.output_dir = ['./output/']\n",
        "            args.train_dir = ['./data/train/']\n",
        "            args.val_dir = ['./data/validation/']\n",
        "            args.epoch = [10]\n",
        "            args.batch = [4]\n",
        "            args.train_model = [True]\n",
        "            args.load_weights = [False]\n",
        "            args.load_checkpoint = [False]\n",
        "            args.fine_tune = [True]\n",
        "            args.test_aug = [False]\n",
        "            args.train_aug = [False]\n",
        "            args.plot = [False]\n",
        "            args.model_summary = [False]\n",
        "            args.dropout = [0.6]\n",
        "            args.learning_rate = [1e-8]\n",
        "            args.decay = [0.0]\n",
        "            args.optimizer_val = ['rms'] # 'rms', 'sgd', 'ada'\n",
        "            args.frozen_layers = [150]\n",
        "            args.base_model = ['inceptionv4']\n",
        "            args.saved_chkpnt\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "\n",
        "    # Get output dir ##########################################################\n",
        "    if not os.path.exists(args.output_dir[0]):\n",
        "        os.makedirs(args.output_dir[0])\n",
        "\n",
        "    # Get optimizer, learning rate, decay parameters ##########################\n",
        "    optimizer_val = args.optimizer_val[0]\n",
        "    lr = args.learning_rate[0]\n",
        "    decay = args.decay[0]\n",
        "\n",
        "    # Set optimizer based on user input #######################################\n",
        "    if optimizer_val.lower() == 'sgd':\n",
        "        optimizer = SGD(lr=lr, decay=decay, momentum=1, nesterov=True)\n",
        "        print(\"Using SGD as the optimizer ...\")\n",
        "    elif optimizer_val.lower() == 'rms' or optimizer_val.lower() == 'rmsprop':\n",
        "        optimizer = RMSprop(lr=lr, rho=0.9, epsilon=1e-08, decay=decay)\n",
        "        print(\"Using RMSProp as the optimizer ...\")\n",
        "    elif optimizer_val.lower() == 'ada':\n",
        "        optimizer = Adagrad(lr=lr, epsilon=1e-08, decay=decay)\n",
        "        print(\"Using Adagrad as the optimizer ...\")\n",
        "    else:\n",
        "        optimizer = DEFAULT_OPTIMIZER\n",
        "\n",
        "    # Get number training samples and classes #################################\n",
        "    nb_train_samples = get_nb_files(args.train_dir[0])\n",
        "    nb_classes = len(glob.glob(args.train_dir[0] + \"/*\"))\n",
        "    print(\"Total number of training samples = \" + str(nb_train_samples))\n",
        "    print(\"Number of training classes = \" + str(nb_classes))\n",
        "\n",
        "    # Get number validation samples and classes ###############################\n",
        "    nb_val_samples = get_nb_files(args.val_dir[0])\n",
        "    nb_val_classes = len(glob.glob(args.val_dir[0] + \"/*\"))\n",
        "    print(\"Total number of validation samples = \" + str(nb_val_samples))\n",
        "    print(\"Number of validation classes = \" + str(nb_val_classes))\n",
        "\n",
        "    # START TRAINING if train labels == valid labels ##########################\n",
        "    if nb_val_classes == nb_classes:\n",
        "        print(\"Initiating training session ...\")\n",
        "    else:\n",
        "        print(\"Mismatched number of training and validation data classes ...\")\n",
        "        print(\"Unequal number of sub-folders found between train and \"\n",
        "              \"validation directories ...\")\n",
        "        print(\"Each sub-folder in train and validation directroies are \"\n",
        "              \"treated as a separate class ...\")\n",
        "        print(\"Correct this mismatch and re-run ...\")\n",
        "        print(\"Now exiting ...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Get num epochs, batch size, train aug ###################################\n",
        "    nb_epoch = int(args.epoch[0])\n",
        "    batch_size = int(args.batch[0])\n",
        "    train_aug = args.train_aug[0]\n",
        "\n",
        "    # Grab Base Model to train op top of  [TRANSF LEARNING] ###################\n",
        "    if str((args.base_model[0]).lower()) == 'inceptionv4' or \\\n",
        "                    str((args.base_model[0]).lower()) == 'inception_v4' or \\\n",
        "                    str((args.base_model[0]).lower()) == 'inception_resnet':\n",
        "        preprocess_input = preprocess_input_inceptionv4\n",
        "    else:\n",
        "        preprocess_input = preprocess_input_inceptionv3\n",
        "\n",
        "    # ?????? ##################################################################\n",
        "    if train_aug == True:\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input)\n",
        "\n",
        "    # ?????? ##################################################################\n",
        "    test_aug = args.test_aug[0]\n",
        "    if test_aug == True:\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    else:\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Getting training data ###################################################\n",
        "    print(\"Generating training data: ... \")\n",
        "    train_generator = train_datagen.flow_from_directory(args.train_dir[0],\n",
        "                                                        target_size=(\n",
        "                                                        IM_WIDTH, IM_HEIGHT),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical')\n",
        "\n",
        "    # Getting validation data #################################################\n",
        "    print(\"Generating validation data: ... \")\n",
        "    validation_generator = test_datagen.flow_from_directory(args.val_dir[0],\n",
        "                                                            target_size=(\n",
        "                                                            IM_WIDTH,\n",
        "                                                            IM_HEIGHT),\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            class_mode='categorical')\n",
        "\n",
        "    # If base model an inception net ##########################################\n",
        "    if str((args.base_model[0]).lower()) == 'inceptionv4' or\\\n",
        "        str((args.base_model[0]).lower()) == 'inception_v4' or\\\n",
        "        str((args.base_model[0]).lower()) == 'inception_resnet':\n",
        "        base_model = InceptionResNetV2(weights='imagenet', \\\n",
        "                                       include_top=False)\n",
        "        base_model_name = 'Inception version 4'\n",
        "    else:\n",
        "        # Model argument: include_top=False excludes the final FC layer\n",
        "        base_model = InceptionV3(weights='imagenet',\n",
        "                                 include_top=False)\n",
        "        base_model_name = 'Inception version 3'\n",
        "    print('Base model: ' + str(base_model_name))\n",
        "\n",
        "    # Add a new layer to the base model #######################################\n",
        "    model = add_top_layer(args, base_model, nb_classes)\n",
        "    print(\"New top layer added to: \" + str(base_model_name))\n",
        "\n",
        "    # get classification labels, if to load checkpoints, previous weights,etc #\n",
        "    labels = generate_labels(args)\n",
        "    load_weights_ = args.load_weights[0]\n",
        "    fine_tune_model = args.fine_tune[0]\n",
        "    load_checkpoint = args.load_checkpoint[0]\n",
        "    checkpointer_savepath = os.path.join(args.output_dir[0] +\n",
        "                                         '/checkpoint/Transfer_learn_' +\n",
        "                                         str(IM_WIDTH) + '_' +\n",
        "                                         str(IM_HEIGHT) + '_' + '.h5')\n",
        "\n",
        "    # Getting previous weights from checkpoint, else new model ################\n",
        "    if load_weights_ == True and load_checkpoint == False:\n",
        "        try:\n",
        "            with open(args.config_file[0]) as json_file:\n",
        "                model_json = json_file.read()\n",
        "            model = model_from_json(model_json)\n",
        "        except:\n",
        "            model = model\n",
        "        try:\n",
        "            model.load_weights(args.weights_file[0])\n",
        "            print(\"Loaded model weights from: \" + str(args.weights_file[0]))\n",
        "        except:\n",
        "            print(\"Error loading model weights ...\")\n",
        "            print(\"Loaded default model weights ...\")\n",
        "    elif load_checkpoint == True:\n",
        "        try:\n",
        "            model = load_model(checkpointer_savepath)\n",
        "            print(\n",
        "                \"Loaded model from checkpoint: \" + str(checkpointer_savepath))\n",
        "        except:\n",
        "            if os.path.exists(args.saved_chkpnt[0]):\n",
        "                model = load_model(args.saved_chkpnt[0])\n",
        "                print('Loaded saved checkpoint file ...')\n",
        "            else:\n",
        "                print(\"Error loading model checkpoint ...\")\n",
        "                print(\"Loaded default model weights ...\")\n",
        "    else:\n",
        "        model = model\n",
        "        print(\"Tabula rasa ...\")\n",
        "\n",
        "    # Checking and freezing certain layers during training ####################\n",
        "    try:\n",
        "        NB_FROZEN_LAYERS = args.frozen_layers[0]\n",
        "    except:\n",
        "        NB_FROZEN_LAYERS = DEFAULT_NB_LAYERS_TO_FREEZE\n",
        "    if fine_tune_model == True:\n",
        "        print(\"Fine tuning Inception architecture ...\")\n",
        "        print(\"Frozen layers: \" + str(NB_FROZEN_LAYERS))\n",
        "        setup_to_finetune(model, optimizer, NB_FROZEN_LAYERS)\n",
        "    else:\n",
        "        print(\"Transfer learning using Inception architecture ...\")\n",
        "        setup_to_transfer_learn(model, base_model, optimizer)\n",
        "\n",
        "    # START TRAINING ##########################################################\n",
        "    print(\"Initializing training with  class labels: \" + str(labels))\n",
        "\n",
        "    # checking and printing current model summary prior to training\n",
        "    model_summary_ = args.model_summary[0]\n",
        "    if model_summary_ == True:\n",
        "        print(model.summary())\n",
        "    else:\n",
        "        print(\n",
        "            \"Successfully loaded deep neural network classifier for training \")\n",
        "\n",
        "    # getting checkpoint file prepared\n",
        "    if not os.path.exists(os.path.join(args.output_dir[0] + '/checkpoint/')):\n",
        "        os.makedirs(os.path.join(args.output_dir[0] + '/checkpoint/'))\n",
        "\n",
        "    # setting up checkpoint, learning rate\n",
        "    earlystopper = EarlyStopping(patience=6, verbose=1)\n",
        "    checkpointer = ModelCheckpoint(checkpointer_savepath,\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True)\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                                patience=2,\n",
        "                                                mode='min',\n",
        "                                                epsilon=1e-4,\n",
        "                                                cooldown=1,\n",
        "                                                verbose=1,\n",
        "                                                factor=0.5,\n",
        "                                                min_lr=lr * 1e-2)\n",
        "    \n",
        "    model.summary()\n",
        "\n",
        "    # training command\n",
        "    model_train = model.fit_generator(train_generator,\n",
        "                                      epochs=nb_epoch,\n",
        "                                      steps_per_epoch=2000,\n",
        "                                      validation_data=validation_generator,\n",
        "                                      validation_steps=2000,\n",
        "                                      class_weight='auto',\n",
        "                                      callbacks=[earlystopper,\n",
        "                                                 learning_rate_reduction,\n",
        "                                                 checkpointer])\n",
        "\n",
        "    # saving model and training plots\n",
        "    if fine_tune_model == True:\n",
        "        save_model(args, \"_ft_\", model)\n",
        "        generate_plot(args, \"_ft_\", model_train)\n",
        "    else:\n",
        "        save_model(args, \"_tl_\", model)\n",
        "        generate_plot(args, \"_tl_\", model_train)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "########################### DEFAULT PARAMETERS ################################\n",
        "\n",
        "IM_WIDTH, IM_HEIGHT = 299, 299  # Fixed input image size for Inception\n",
        "DEFAULT_EPOCHS = 100\n",
        "DEFAULT_BATCHES = 20\n",
        "FC_SIZE = 4096\n",
        "DEFAULT_DROPOUT = 0.1\n",
        "DEFAULT_NB_LAYERS_TO_FREEZE = 169\n",
        "\n",
        "sgd = SGD(lr=1e-7, decay=0.5, momentum=1, nesterov=True)\n",
        "rms = RMSprop(lr=1e-7, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "ada = Adagrad(lr=1e-3, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "DEFAULT_OPTIMIZER = ada\n",
        "timestr = generate_timestamp()\n",
        "###############################################################################"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time stamp generated: 2019_06_02-15_35_56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHK7SQjtqhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import types\n",
        "\n",
        "model_dir = \"./drive/EFIGI_Galaxy_Classification/model/\"\n",
        "output_dir = \"./drive/EFIGI_Galaxy_Classification/output/\"\n",
        "checkpoint_dir = \"./drive/EFIGI_Galaxy_Classification/output/checkpoint/\"\n",
        "\n",
        "\n",
        "args = types.SimpleNamespace()\n",
        "args.config_file = [model_dir+'model_efc.json']\n",
        "args.output_dir = [output_dir]\n",
        "args.train_dir = ['./data/train/']\n",
        "args.val_dir = ['./data/validation/']\n",
        "args.epoch = [100]# at least 100 epochs\n",
        "args.batch = [60]\n",
        "args.train_model = [True]\n",
        "args.load_weights = [False]\n",
        "args.load_checkpoint = [True] # Set it to true for using a saved checkpoint\n",
        "args.fine_tune = [True]\n",
        "args.test_aug = [False]\n",
        "args.train_aug = [False]\n",
        "args.plot = [True]\n",
        "args.model_summary = [False]\n",
        "args.dropout = [0.95]\n",
        "args.learning_rate = [1e-3]\n",
        "args.decay = [0.0]\n",
        "args.optimizer_val = ['adam'] # 'rms', 'sgd', 'ada'\n",
        "args.frozen_layers = [140]\n",
        "args.base_model = ['inceptionv4']\n",
        "args.saved_chkpnt = [checkpoint_dir+'transfer_learn_299_299_.h5']\n",
        "args.activation = ['elu']\n",
        "\n",
        "\n",
        "def ensure_dir(file_path):\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "ensure_dir(model_dir)\n",
        "ensure_dir(output_dir)\n",
        "ensure_dir(checkpoint_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL_tT3buttew",
        "colab_type": "code",
        "outputId": "86230c99-0664-46d1-eb39-da0c8019648e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29736
        }
      },
      "source": [
        "train_model = args.train_model[0]\n",
        "    \n",
        "if train_model ==True:\n",
        "  print (\"Training sesssion initiated ...\")\n",
        "  train(args)\n",
        "else:\n",
        "  print (\"Nothing to do here ...\")\n",
        "  print (\"Try setting the --train_model flag to True ...\")\n",
        "  print (\"For more help, run with -h flag ...\")\n",
        "  sys.exit(1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training sesssion initiated ...\n",
            "Total number of training samples = 21401\n",
            "Number of training classes = 5\n",
            "Total number of validation samples = 9625\n",
            "Number of validation classes = 5\n",
            "Initiating training session ...\n",
            "Generating training data: ... \n",
            "Found 21401 images belonging to 5 classes.\n",
            "Generating validation data: ... \n",
            "Found 9625 images belonging to 5 classes.\n",
            "Base model: Inception version 4\n",
            "Invalid user input ...\n",
            "Building model using activation function: elu\n",
            "New top layer added to: Inception version 4\n",
            "Training labels: ['DWARF', 'ELLIPTICAL', 'IRREGULAR', 'LENTICULAR', 'SPIRAL']\n",
            "Validation labels: ['DWARF', 'ELLIPTICAL', 'IRREGULAR', 'LENTICULAR', 'SPIRAL']\n",
            "Error loading model checkpoint ...\n",
            "Loaded default model weights ...\n",
            "Fine tuning Inception architecture ...\n",
            "Frozen layers: 140\n",
            "Initializing training with  class labels: ['DWARF', 'ELLIPTICAL', 'IRREGULAR', 'LENTICULAR', 'SPIRAL']\n",
            "Successfully loaded deep neural network classifier for training \n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_204 (Conv2D)             (None, None, None, 3 864         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_204 (BatchN (None, None, None, 3 96          conv2d_204[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_204 (Activation)     (None, None, None, 3 0           batch_normalization_204[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_205 (Conv2D)             (None, None, None, 3 9216        activation_204[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_205 (BatchN (None, None, None, 3 96          conv2d_205[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_205 (Activation)     (None, None, None, 3 0           batch_normalization_205[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_206 (Conv2D)             (None, None, None, 6 18432       activation_205[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_206 (BatchN (None, None, None, 6 192         conv2d_206[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_206 (Activation)     (None, None, None, 6 0           batch_normalization_206[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2D)  (None, None, None, 6 0           activation_206[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_207 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_5[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_207 (BatchN (None, None, None, 8 240         conv2d_207[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_207 (Activation)     (None, None, None, 8 0           batch_normalization_207[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_208 (Conv2D)             (None, None, None, 1 138240      activation_207[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_208 (BatchN (None, None, None, 1 576         conv2d_208[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_208 (Activation)     (None, None, None, 1 0           batch_normalization_208[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2D)  (None, None, None, 1 0           activation_208[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_212 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_212 (BatchN (None, None, None, 6 192         conv2d_212[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_212 (Activation)     (None, None, None, 6 0           batch_normalization_212[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_210 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_213 (Conv2D)             (None, None, None, 9 55296       activation_212[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_210 (BatchN (None, None, None, 4 144         conv2d_210[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_213 (BatchN (None, None, None, 9 288         conv2d_213[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_210 (Activation)     (None, None, None, 4 0           batch_normalization_210[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_213 (Activation)     (None, None, None, 9 0           batch_normalization_213[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, None, None, 1 0           max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_209 (Conv2D)             (None, None, None, 9 18432       max_pooling2d_6[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_211 (Conv2D)             (None, None, None, 6 76800       activation_210[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_214 (Conv2D)             (None, None, None, 9 82944       activation_213[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_215 (Conv2D)             (None, None, None, 6 12288       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_209 (BatchN (None, None, None, 9 288         conv2d_209[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_211 (BatchN (None, None, None, 6 192         conv2d_211[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_214 (BatchN (None, None, None, 9 288         conv2d_214[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_215 (BatchN (None, None, None, 6 192         conv2d_215[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_209 (Activation)     (None, None, None, 9 0           batch_normalization_209[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_211 (Activation)     (None, None, None, 6 0           batch_normalization_211[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_214 (Activation)     (None, None, None, 9 0           batch_normalization_214[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_215 (Activation)     (None, None, None, 6 0           batch_normalization_215[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed_5b (Concatenate)          (None, None, None, 3 0           activation_209[0][0]             \n",
            "                                                                 activation_211[0][0]             \n",
            "                                                                 activation_214[0][0]             \n",
            "                                                                 activation_215[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_219 (Conv2D)             (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_219 (BatchN (None, None, None, 3 96          conv2d_219[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_219 (Activation)     (None, None, None, 3 0           batch_normalization_219[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_217 (Conv2D)             (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_220 (Conv2D)             (None, None, None, 4 13824       activation_219[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_217 (BatchN (None, None, None, 3 96          conv2d_217[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_220 (BatchN (None, None, None, 4 144         conv2d_220[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_217 (Activation)     (None, None, None, 3 0           batch_normalization_217[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_220 (Activation)     (None, None, None, 4 0           batch_normalization_220[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_216 (Conv2D)             (None, None, None, 3 10240       mixed_5b[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_218 (Conv2D)             (None, None, None, 3 9216        activation_217[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_221 (Conv2D)             (None, None, None, 6 27648       activation_220[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_216 (BatchN (None, None, None, 3 96          conv2d_216[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_218 (BatchN (None, None, None, 3 96          conv2d_218[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_221 (BatchN (None, None, None, 6 192         conv2d_221[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_216 (Activation)     (None, None, None, 3 0           batch_normalization_216[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_218 (Activation)     (None, None, None, 3 0           batch_normalization_218[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_221 (Activation)     (None, None, None, 6 0           batch_normalization_221[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_mixed (Concatenate)   (None, None, None, 1 0           activation_216[0][0]             \n",
            "                                                                 activation_218[0][0]             \n",
            "                                                                 activation_221[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_conv (Conv2D)         (None, None, None, 3 41280       block35_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_1 (Lambda)              (None, None, None, 3 0           mixed_5b[0][0]                   \n",
            "                                                                 block35_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_1_ac (Activation)       (None, None, None, 3 0           block35_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_225 (Conv2D)             (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_225 (BatchN (None, None, None, 3 96          conv2d_225[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_225 (Activation)     (None, None, None, 3 0           batch_normalization_225[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_223 (Conv2D)             (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_226 (Conv2D)             (None, None, None, 4 13824       activation_225[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_223 (BatchN (None, None, None, 3 96          conv2d_223[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_226 (BatchN (None, None, None, 4 144         conv2d_226[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_223 (Activation)     (None, None, None, 3 0           batch_normalization_223[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_226 (Activation)     (None, None, None, 4 0           batch_normalization_226[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_222 (Conv2D)             (None, None, None, 3 10240       block35_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_224 (Conv2D)             (None, None, None, 3 9216        activation_223[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_227 (Conv2D)             (None, None, None, 6 27648       activation_226[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_222 (BatchN (None, None, None, 3 96          conv2d_222[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_224 (BatchN (None, None, None, 3 96          conv2d_224[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_227 (BatchN (None, None, None, 6 192         conv2d_227[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_222 (Activation)     (None, None, None, 3 0           batch_normalization_222[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_224 (Activation)     (None, None, None, 3 0           batch_normalization_224[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_227 (Activation)     (None, None, None, 6 0           batch_normalization_227[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_mixed (Concatenate)   (None, None, None, 1 0           activation_222[0][0]             \n",
            "                                                                 activation_224[0][0]             \n",
            "                                                                 activation_227[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_conv (Conv2D)         (None, None, None, 3 41280       block35_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_2 (Lambda)              (None, None, None, 3 0           block35_1_ac[0][0]               \n",
            "                                                                 block35_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_2_ac (Activation)       (None, None, None, 3 0           block35_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_231 (Conv2D)             (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_231 (BatchN (None, None, None, 3 96          conv2d_231[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_231 (Activation)     (None, None, None, 3 0           batch_normalization_231[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_229 (Conv2D)             (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_232 (Conv2D)             (None, None, None, 4 13824       activation_231[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_229 (BatchN (None, None, None, 3 96          conv2d_229[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_232 (BatchN (None, None, None, 4 144         conv2d_232[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_229 (Activation)     (None, None, None, 3 0           batch_normalization_229[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_232 (Activation)     (None, None, None, 4 0           batch_normalization_232[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_228 (Conv2D)             (None, None, None, 3 10240       block35_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_230 (Conv2D)             (None, None, None, 3 9216        activation_229[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_233 (Conv2D)             (None, None, None, 6 27648       activation_232[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_228 (BatchN (None, None, None, 3 96          conv2d_228[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_230 (BatchN (None, None, None, 3 96          conv2d_230[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_233 (BatchN (None, None, None, 6 192         conv2d_233[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_228 (Activation)     (None, None, None, 3 0           batch_normalization_228[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_230 (Activation)     (None, None, None, 3 0           batch_normalization_230[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_233 (Activation)     (None, None, None, 6 0           batch_normalization_233[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_mixed (Concatenate)   (None, None, None, 1 0           activation_228[0][0]             \n",
            "                                                                 activation_230[0][0]             \n",
            "                                                                 activation_233[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_conv (Conv2D)         (None, None, None, 3 41280       block35_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_3 (Lambda)              (None, None, None, 3 0           block35_2_ac[0][0]               \n",
            "                                                                 block35_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_3_ac (Activation)       (None, None, None, 3 0           block35_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_237 (Conv2D)             (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_237 (BatchN (None, None, None, 3 96          conv2d_237[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_237 (Activation)     (None, None, None, 3 0           batch_normalization_237[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_235 (Conv2D)             (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_238 (Conv2D)             (None, None, None, 4 13824       activation_237[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_235 (BatchN (None, None, None, 3 96          conv2d_235[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_238 (BatchN (None, None, None, 4 144         conv2d_238[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_235 (Activation)     (None, None, None, 3 0           batch_normalization_235[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_238 (Activation)     (None, None, None, 4 0           batch_normalization_238[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_234 (Conv2D)             (None, None, None, 3 10240       block35_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_236 (Conv2D)             (None, None, None, 3 9216        activation_235[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_239 (Conv2D)             (None, None, None, 6 27648       activation_238[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_234 (BatchN (None, None, None, 3 96          conv2d_234[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_236 (BatchN (None, None, None, 3 96          conv2d_236[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_239 (BatchN (None, None, None, 6 192         conv2d_239[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_234 (Activation)     (None, None, None, 3 0           batch_normalization_234[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_236 (Activation)     (None, None, None, 3 0           batch_normalization_236[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_239 (Activation)     (None, None, None, 6 0           batch_normalization_239[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_mixed (Concatenate)   (None, None, None, 1 0           activation_234[0][0]             \n",
            "                                                                 activation_236[0][0]             \n",
            "                                                                 activation_239[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_conv (Conv2D)         (None, None, None, 3 41280       block35_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_4 (Lambda)              (None, None, None, 3 0           block35_3_ac[0][0]               \n",
            "                                                                 block35_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_4_ac (Activation)       (None, None, None, 3 0           block35_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_243 (Conv2D)             (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_243 (BatchN (None, None, None, 3 96          conv2d_243[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_243 (Activation)     (None, None, None, 3 0           batch_normalization_243[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_241 (Conv2D)             (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_244 (Conv2D)             (None, None, None, 4 13824       activation_243[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_241 (BatchN (None, None, None, 3 96          conv2d_241[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_244 (BatchN (None, None, None, 4 144         conv2d_244[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_241 (Activation)     (None, None, None, 3 0           batch_normalization_241[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_244 (Activation)     (None, None, None, 4 0           batch_normalization_244[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_240 (Conv2D)             (None, None, None, 3 10240       block35_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_242 (Conv2D)             (None, None, None, 3 9216        activation_241[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_245 (Conv2D)             (None, None, None, 6 27648       activation_244[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_240 (BatchN (None, None, None, 3 96          conv2d_240[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_242 (BatchN (None, None, None, 3 96          conv2d_242[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_245 (BatchN (None, None, None, 6 192         conv2d_245[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_240 (Activation)     (None, None, None, 3 0           batch_normalization_240[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_242 (Activation)     (None, None, None, 3 0           batch_normalization_242[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_245 (Activation)     (None, None, None, 6 0           batch_normalization_245[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_mixed (Concatenate)   (None, None, None, 1 0           activation_240[0][0]             \n",
            "                                                                 activation_242[0][0]             \n",
            "                                                                 activation_245[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_conv (Conv2D)         (None, None, None, 3 41280       block35_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_5 (Lambda)              (None, None, None, 3 0           block35_4_ac[0][0]               \n",
            "                                                                 block35_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_5_ac (Activation)       (None, None, None, 3 0           block35_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_249 (Conv2D)             (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_249 (BatchN (None, None, None, 3 96          conv2d_249[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_249 (Activation)     (None, None, None, 3 0           batch_normalization_249[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_247 (Conv2D)             (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_250 (Conv2D)             (None, None, None, 4 13824       activation_249[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_247 (BatchN (None, None, None, 3 96          conv2d_247[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_250 (BatchN (None, None, None, 4 144         conv2d_250[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_247 (Activation)     (None, None, None, 3 0           batch_normalization_247[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_250 (Activation)     (None, None, None, 4 0           batch_normalization_250[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_246 (Conv2D)             (None, None, None, 3 10240       block35_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_248 (Conv2D)             (None, None, None, 3 9216        activation_247[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_251 (Conv2D)             (None, None, None, 6 27648       activation_250[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_246 (BatchN (None, None, None, 3 96          conv2d_246[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_248 (BatchN (None, None, None, 3 96          conv2d_248[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_251 (BatchN (None, None, None, 6 192         conv2d_251[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_246 (Activation)     (None, None, None, 3 0           batch_normalization_246[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_248 (Activation)     (None, None, None, 3 0           batch_normalization_248[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_251 (Activation)     (None, None, None, 6 0           batch_normalization_251[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_mixed (Concatenate)   (None, None, None, 1 0           activation_246[0][0]             \n",
            "                                                                 activation_248[0][0]             \n",
            "                                                                 activation_251[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_conv (Conv2D)         (None, None, None, 3 41280       block35_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_6 (Lambda)              (None, None, None, 3 0           block35_5_ac[0][0]               \n",
            "                                                                 block35_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_6_ac (Activation)       (None, None, None, 3 0           block35_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_255 (Conv2D)             (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_255 (BatchN (None, None, None, 3 96          conv2d_255[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_255 (Activation)     (None, None, None, 3 0           batch_normalization_255[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_253 (Conv2D)             (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_256 (Conv2D)             (None, None, None, 4 13824       activation_255[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_253 (BatchN (None, None, None, 3 96          conv2d_253[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_256 (BatchN (None, None, None, 4 144         conv2d_256[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_253 (Activation)     (None, None, None, 3 0           batch_normalization_253[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_256 (Activation)     (None, None, None, 4 0           batch_normalization_256[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_252 (Conv2D)             (None, None, None, 3 10240       block35_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_254 (Conv2D)             (None, None, None, 3 9216        activation_253[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_257 (Conv2D)             (None, None, None, 6 27648       activation_256[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_252 (BatchN (None, None, None, 3 96          conv2d_252[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_254 (BatchN (None, None, None, 3 96          conv2d_254[0][0]                 "
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1065: UserWarning: `epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
            "  warnings.warn('`epsilon` argument is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_257 (BatchN (None, None, None, 6 192         conv2d_257[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_252 (Activation)     (None, None, None, 3 0           batch_normalization_252[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_254 (Activation)     (None, None, None, 3 0           batch_normalization_254[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_257 (Activation)     (None, None, None, 6 0           batch_normalization_257[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_mixed (Concatenate)   (None, None, None, 1 0           activation_252[0][0]             \n",
            "                                                                 activation_254[0][0]             \n",
            "                                                                 activation_257[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_conv (Conv2D)         (None, None, None, 3 41280       block35_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_7 (Lambda)              (None, None, None, 3 0           block35_6_ac[0][0]               \n",
            "                                                                 block35_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_7_ac (Activation)       (None, None, None, 3 0           block35_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_261 (Conv2D)             (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_261 (BatchN (None, None, None, 3 96          conv2d_261[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_261 (Activation)     (None, None, None, 3 0           batch_normalization_261[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_259 (Conv2D)             (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_262 (Conv2D)             (None, None, None, 4 13824       activation_261[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_259 (BatchN (None, None, None, 3 96          conv2d_259[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_262 (BatchN (None, None, None, 4 144         conv2d_262[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_259 (Activation)     (None, None, None, 3 0           batch_normalization_259[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_262 (Activation)     (None, None, None, 4 0           batch_normalization_262[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_258 (Conv2D)             (None, None, None, 3 10240       block35_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_260 (Conv2D)             (None, None, None, 3 9216        activation_259[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_263 (Conv2D)             (None, None, None, 6 27648       activation_262[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_258 (BatchN (None, None, None, 3 96          conv2d_258[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_260 (BatchN (None, None, None, 3 96          conv2d_260[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_263 (BatchN (None, None, None, 6 192         conv2d_263[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_258 (Activation)     (None, None, None, 3 0           batch_normalization_258[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_260 (Activation)     (None, None, None, 3 0           batch_normalization_260[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_263 (Activation)     (None, None, None, 6 0           batch_normalization_263[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_mixed (Concatenate)   (None, None, None, 1 0           activation_258[0][0]             \n",
            "                                                                 activation_260[0][0]             \n",
            "                                                                 activation_263[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_conv (Conv2D)         (None, None, None, 3 41280       block35_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_8 (Lambda)              (None, None, None, 3 0           block35_7_ac[0][0]               \n",
            "                                                                 block35_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_8_ac (Activation)       (None, None, None, 3 0           block35_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_267 (Conv2D)             (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_267 (BatchN (None, None, None, 3 96          conv2d_267[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_267 (Activation)     (None, None, None, 3 0           batch_normalization_267[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_265 (Conv2D)             (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_268 (Conv2D)             (None, None, None, 4 13824       activation_267[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_265 (BatchN (None, None, None, 3 96          conv2d_265[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_268 (BatchN (None, None, None, 4 144         conv2d_268[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_265 (Activation)     (None, None, None, 3 0           batch_normalization_265[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_268 (Activation)     (None, None, None, 4 0           batch_normalization_268[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_264 (Conv2D)             (None, None, None, 3 10240       block35_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_266 (Conv2D)             (None, None, None, 3 9216        activation_265[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_269 (Conv2D)             (None, None, None, 6 27648       activation_268[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_264 (BatchN (None, None, None, 3 96          conv2d_264[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_266 (BatchN (None, None, None, 3 96          conv2d_266[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_269 (BatchN (None, None, None, 6 192         conv2d_269[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_264 (Activation)     (None, None, None, 3 0           batch_normalization_264[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_266 (Activation)     (None, None, None, 3 0           batch_normalization_266[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_269 (Activation)     (None, None, None, 6 0           batch_normalization_269[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_mixed (Concatenate)   (None, None, None, 1 0           activation_264[0][0]             \n",
            "                                                                 activation_266[0][0]             \n",
            "                                                                 activation_269[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_conv (Conv2D)         (None, None, None, 3 41280       block35_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_9 (Lambda)              (None, None, None, 3 0           block35_8_ac[0][0]               \n",
            "                                                                 block35_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_9_ac (Activation)       (None, None, None, 3 0           block35_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_273 (Conv2D)             (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_273 (BatchN (None, None, None, 3 96          conv2d_273[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_273 (Activation)     (None, None, None, 3 0           batch_normalization_273[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_271 (Conv2D)             (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_274 (Conv2D)             (None, None, None, 4 13824       activation_273[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_271 (BatchN (None, None, None, 3 96          conv2d_271[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_274 (BatchN (None, None, None, 4 144         conv2d_274[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_271 (Activation)     (None, None, None, 3 0           batch_normalization_271[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_274 (Activation)     (None, None, None, 4 0           batch_normalization_274[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_270 (Conv2D)             (None, None, None, 3 10240       block35_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_272 (Conv2D)             (None, None, None, 3 9216        activation_271[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_275 (Conv2D)             (None, None, None, 6 27648       activation_274[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_270 (BatchN (None, None, None, 3 96          conv2d_270[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_272 (BatchN (None, None, None, 3 96          conv2d_272[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_275 (BatchN (None, None, None, 6 192         conv2d_275[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_270 (Activation)     (None, None, None, 3 0           batch_normalization_270[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_272 (Activation)     (None, None, None, 3 0           batch_normalization_272[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_275 (Activation)     (None, None, None, 6 0           batch_normalization_275[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_mixed (Concatenate)  (None, None, None, 1 0           activation_270[0][0]             \n",
            "                                                                 activation_272[0][0]             \n",
            "                                                                 activation_275[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_conv (Conv2D)        (None, None, None, 3 41280       block35_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block35_10 (Lambda)             (None, None, None, 3 0           block35_9_ac[0][0]               \n",
            "                                                                 block35_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block35_10_ac (Activation)      (None, None, None, 3 0           block35_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_277 (Conv2D)             (None, None, None, 2 81920       block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_277 (BatchN (None, None, None, 2 768         conv2d_277[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_277 (Activation)     (None, None, None, 2 0           batch_normalization_277[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_278 (Conv2D)             (None, None, None, 2 589824      activation_277[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_278 (BatchN (None, None, None, 2 768         conv2d_278[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_278 (Activation)     (None, None, None, 2 0           batch_normalization_278[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_276 (Conv2D)             (None, None, None, 3 1105920     block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_279 (Conv2D)             (None, None, None, 3 884736      activation_278[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_276 (BatchN (None, None, None, 3 1152        conv2d_276[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_279 (BatchN (None, None, None, 3 1152        conv2d_279[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_276 (Activation)     (None, None, None, 3 0           batch_normalization_276[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_279 (Activation)     (None, None, None, 3 0           batch_normalization_279[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2D)  (None, None, None, 3 0           block35_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_6a (Concatenate)          (None, None, None, 1 0           activation_276[0][0]             \n",
            "                                                                 activation_279[0][0]             \n",
            "                                                                 max_pooling2d_7[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_281 (Conv2D)             (None, None, None, 1 139264      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_281 (BatchN (None, None, None, 1 384         conv2d_281[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_281 (Activation)     (None, None, None, 1 0           batch_normalization_281[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_282 (Conv2D)             (None, None, None, 1 143360      activation_281[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_282 (BatchN (None, None, None, 1 480         conv2d_282[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_282 (Activation)     (None, None, None, 1 0           batch_normalization_282[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_280 (Conv2D)             (None, None, None, 1 208896      mixed_6a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_283 (Conv2D)             (None, None, None, 1 215040      activation_282[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_280 (BatchN (None, None, None, 1 576         conv2d_280[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_283 (BatchN (None, None, None, 1 576         conv2d_283[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_280 (Activation)     (None, None, None, 1 0           batch_normalization_280[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_283 (Activation)     (None, None, None, 1 0           batch_normalization_283[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_mixed (Concatenate)   (None, None, None, 3 0           activation_280[0][0]             \n",
            "                                                                 activation_283[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_conv (Conv2D)         (None, None, None, 1 418880      block17_1_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_1 (Lambda)              (None, None, None, 1 0           mixed_6a[0][0]                   \n",
            "                                                                 block17_1_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_1_ac (Activation)       (None, None, None, 1 0           block17_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_285 (Conv2D)             (None, None, None, 1 139264      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, None, None, 1 384         conv2d_285[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, None, None, 1 0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_286 (Conv2D)             (None, None, None, 1 143360      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, None, None, 1 480         conv2d_286[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, None, None, 1 0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_284 (Conv2D)             (None, None, None, 1 208896      block17_1_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_287 (Conv2D)             (None, None, None, 1 215040      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, None, None, 1 576         conv2d_284[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, None, None, 1 576         conv2d_287[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, None, None, 1 0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, None, None, 1 0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_mixed (Concatenate)   (None, None, None, 3 0           activation_284[0][0]             \n",
            "                                                                 activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_conv (Conv2D)         (None, None, None, 1 418880      block17_2_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_2 (Lambda)              (None, None, None, 1 0           block17_1_ac[0][0]               \n",
            "                                                                 block17_2_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_2_ac (Activation)       (None, None, None, 1 0           block17_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_289 (Conv2D)             (None, None, None, 1 139264      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, None, None, 1 384         conv2d_289[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, None, None, 1 0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_290 (Conv2D)             (None, None, None, 1 143360      activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, None, None, 1 480         conv2d_290[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, None, None, 1 0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_288 (Conv2D)             (None, None, None, 1 208896      block17_2_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_291 (Conv2D)             (None, None, None, 1 215040      activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, None, None, 1 576         conv2d_288[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, None, None, 1 576         conv2d_291[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, None, None, 1 0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, None, None, 1 0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_mixed (Concatenate)   (None, None, None, 3 0           activation_288[0][0]             \n",
            "                                                                 activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_conv (Conv2D)         (None, None, None, 1 418880      block17_3_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_3 (Lambda)              (None, None, None, 1 0           block17_2_ac[0][0]               \n",
            "                                                                 block17_3_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_3_ac (Activation)       (None, None, None, 1 0           block17_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_293 (Conv2D)             (None, None, None, 1 139264      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, None, None, 1 384         conv2d_293[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, None, None, 1 0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_294 (Conv2D)             (None, None, None, 1 143360      activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, None, None, 1 480         conv2d_294[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, None, None, 1 0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_292 (Conv2D)             (None, None, None, 1 208896      block17_3_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_295 (Conv2D)             (None, None, None, 1 215040      activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, None, None, 1 576         conv2d_292[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, None, None, 1 576         conv2d_295[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, None, None, 1 0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, None, None, 1 0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_mixed (Concatenate)   (None, None, None, 3 0           activation_292[0][0]             \n",
            "                                                                 activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_conv (Conv2D)         (None, None, None, 1 418880      block17_4_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_4 (Lambda)              (None, None, None, 1 0           block17_3_ac[0][0]               \n",
            "                                                                 block17_4_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_4_ac (Activation)       (None, None, None, 1 0           block17_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_297 (Conv2D)             (None, None, None, 1 139264      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, None, None, 1 384         conv2d_297[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, None, None, 1 0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_298 (Conv2D)             (None, None, None, 1 143360      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, None, None, 1 480         conv2d_298[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, None, None, 1 0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_296 (Conv2D)             (None, None, None, 1 208896      block17_4_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_299 (Conv2D)             (None, None, None, 1 215040      activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, None, None, 1 576         conv2d_296[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, None, None, 1 576         conv2d_299[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, None, None, 1 0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, None, None, 1 0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_mixed (Concatenate)   (None, None, None, 3 0           activation_296[0][0]             \n",
            "                                                                 activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_conv (Conv2D)         (None, None, None, 1 418880      block17_5_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_5 (Lambda)              (None, None, None, 1 0           block17_4_ac[0][0]               \n",
            "                                                                 block17_5_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_5_ac (Activation)       (None, None, None, 1 0           block17_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_301 (Conv2D)             (None, None, None, 1 139264      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, None, None, 1 384         conv2d_301[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, None, None, 1 0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_302 (Conv2D)             (None, None, None, 1 143360      activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, None, None, 1 480         conv2d_302[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, None, None, 1 0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_300 (Conv2D)             (None, None, None, 1 208896      block17_5_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_303 (Conv2D)             (None, None, None, 1 215040      activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, None, None, 1 576         conv2d_300[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, None, None, 1 576         conv2d_303[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, None, None, 1 0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, None, None, 1 0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_mixed (Concatenate)   (None, None, None, 3 0           activation_300[0][0]             \n",
            "                                                                 activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_conv (Conv2D)         (None, None, None, 1 418880      block17_6_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_6 (Lambda)              (None, None, None, 1 0           block17_5_ac[0][0]               \n",
            "                                                                 block17_6_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_6_ac (Activation)       (None, None, None, 1 0           block17_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_305 (Conv2D)             (None, None, None, 1 139264      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, None, None, 1 384         conv2d_305[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, None, None, 1 0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_306 (Conv2D)             (None, None, None, 1 143360      activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, None, None, 1 480         conv2d_306[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, None, None, 1 0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_304 (Conv2D)             (None, None, None, 1 208896      block17_6_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_307 (Conv2D)             (None, None, None, 1 215040      activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, None, None, 1 576         conv2d_304[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, None, None, 1 576         conv2d_307[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, None, None, 1 0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, None, None, 1 0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_mixed (Concatenate)   (None, None, None, 3 0           activation_304[0][0]             \n",
            "                                                                 activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_conv (Conv2D)         (None, None, None, 1 418880      block17_7_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_7 (Lambda)              (None, None, None, 1 0           block17_6_ac[0][0]               \n",
            "                                                                 block17_7_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_7_ac (Activation)       (None, None, None, 1 0           block17_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, None, None, 1 139264      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_309 (BatchN (None, None, None, 1 384         conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_309 (Activation)     (None, None, None, 1 0           batch_normalization_309[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, None, None, 1 143360      activation_309[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_310 (BatchN (None, None, None, 1 480         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_310 (Activation)     (None, None, None, 1 0           batch_normalization_310[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, None, None, 1 208896      block17_7_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, None, None, 1 215040      activation_310[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, None, None, 1 576         conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_311 (BatchN (None, None, None, 1 576         conv2d_311[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, None, None, 1 0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_311 (Activation)     (None, None, None, 1 0           batch_normalization_311[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_mixed (Concatenate)   (None, None, None, 3 0           activation_308[0][0]             \n",
            "                                                                 activation_311[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_conv (Conv2D)         (None, None, None, 1 418880      block17_8_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_8 (Lambda)              (None, None, None, 1 0           block17_7_ac[0][0]               \n",
            "                                                                 block17_8_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_8_ac (Activation)       (None, None, None, 1 0           block17_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, None, None, 1 139264      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_313 (BatchN (None, None, None, 1 384         conv2d_313[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_313 (Activation)     (None, None, None, 1 0           batch_normalization_313[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, None, None, 1 143360      activation_313[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_314 (BatchN (None, None, None, 1 480         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_314 (Activation)     (None, None, None, 1 0           batch_normalization_314[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, None, None, 1 208896      block17_8_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, None, None, 1 215040      activation_314[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_312 (BatchN (None, None, None, 1 576         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_315 (BatchN (None, None, None, 1 576         conv2d_315[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_312 (Activation)     (None, None, None, 1 0           batch_normalization_312[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_315 (Activation)     (None, None, None, 1 0           batch_normalization_315[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_mixed (Concatenate)   (None, None, None, 3 0           activation_312[0][0]             \n",
            "                                                                 activation_315[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_conv (Conv2D)         (None, None, None, 1 418880      block17_9_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_9 (Lambda)              (None, None, None, 1 0           block17_8_ac[0][0]               \n",
            "                                                                 block17_9_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_9_ac (Activation)       (None, None, None, 1 0           block17_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, None, None, 1 139264      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_317 (BatchN (None, None, None, 1 384         conv2d_317[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_317 (Activation)     (None, None, None, 1 0           batch_normalization_317[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, None, None, 1 143360      activation_317[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_318 (BatchN (None, None, None, 1 480         conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_318 (Activation)     (None, None, None, 1 0           batch_normalization_318[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, None, None, 1 208896      block17_9_ac[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, None, None, 1 215040      activation_318[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_316 (BatchN (None, None, None, 1 576         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_319 (BatchN (None, None, None, 1 576         conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_316 (Activation)     (None, None, None, 1 0           batch_normalization_316[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_319 (Activation)     (None, None, None, 1 0           batch_normalization_319[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_mixed (Concatenate)  (None, None, None, 3 0           activation_316[0][0]             \n",
            "                                                                 activation_319[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_conv (Conv2D)        (None, None, None, 1 418880      block17_10_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_10 (Lambda)             (None, None, None, 1 0           block17_9_ac[0][0]               \n",
            "                                                                 block17_10_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_10_ac (Activation)      (None, None, None, 1 0           block17_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, None, None, 1 139264      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_321 (BatchN (None, None, None, 1 384         conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_321 (Activation)     (None, None, None, 1 0           batch_normalization_321[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, None, None, 1 143360      activation_321[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_322 (BatchN (None, None, None, 1 480         conv2d_322[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_322 (Activation)     (None, None, None, 1 0           batch_normalization_322[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, None, None, 1 208896      block17_10_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, None, None, 1 215040      activation_322[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_320 (BatchN (None, None, None, 1 576         conv2d_320[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_323 (BatchN (None, None, None, 1 576         conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_320 (Activation)     (None, None, None, 1 0           batch_normalization_320[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_323 (Activation)     (None, None, None, 1 0           batch_normalization_323[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_mixed (Concatenate)  (None, None, None, 3 0           activation_320[0][0]             \n",
            "                                                                 activation_323[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_conv (Conv2D)        (None, None, None, 1 418880      block17_11_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_11 (Lambda)             (None, None, None, 1 0           block17_10_ac[0][0]              \n",
            "                                                                 block17_11_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_11_ac (Activation)      (None, None, None, 1 0           block17_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, None, None, 1 139264      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_325 (BatchN (None, None, None, 1 384         conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_325 (Activation)     (None, None, None, 1 0           batch_normalization_325[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, None, None, 1 143360      activation_325[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_326 (BatchN (None, None, None, 1 480         conv2d_326[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_326 (Activation)     (None, None, None, 1 0           batch_normalization_326[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, None, None, 1 208896      block17_11_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, None, None, 1 215040      activation_326[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_324 (BatchN (None, None, None, 1 576         conv2d_324[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_327 (BatchN (None, None, None, 1 576         conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_324 (Activation)     (None, None, None, 1 0           batch_normalization_324[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_327 (Activation)     (None, None, None, 1 0           batch_normalization_327[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_mixed (Concatenate)  (None, None, None, 3 0           activation_324[0][0]             \n",
            "                                                                 activation_327[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_conv (Conv2D)        (None, None, None, 1 418880      block17_12_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_12 (Lambda)             (None, None, None, 1 0           block17_11_ac[0][0]              \n",
            "                                                                 block17_12_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_12_ac (Activation)      (None, None, None, 1 0           block17_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, None, None, 1 139264      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_329 (BatchN (None, None, None, 1 384         conv2d_329[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_329 (Activation)     (None, None, None, 1 0           batch_normalization_329[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, None, None, 1 143360      activation_329[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_330 (BatchN (None, None, None, 1 480         conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_330 (Activation)     (None, None, None, 1 0           batch_normalization_330[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, None, None, 1 208896      block17_12_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, None, None, 1 215040      activation_330[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_328 (BatchN (None, None, None, 1 576         conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_331 (BatchN (None, None, None, 1 576         conv2d_331[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_328 (Activation)     (None, None, None, 1 0           batch_normalization_328[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_331 (Activation)     (None, None, None, 1 0           batch_normalization_331[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_mixed (Concatenate)  (None, None, None, 3 0           activation_328[0][0]             \n",
            "                                                                 activation_331[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_conv (Conv2D)        (None, None, None, 1 418880      block17_13_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_13 (Lambda)             (None, None, None, 1 0           block17_12_ac[0][0]              \n",
            "                                                                 block17_13_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_13_ac (Activation)      (None, None, None, 1 0           block17_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, None, None, 1 139264      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_333 (BatchN (None, None, None, 1 384         conv2d_333[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_333 (Activation)     (None, None, None, 1 0           batch_normalization_333[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, None, None, 1 143360      activation_333[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_334 (BatchN (None, None, None, 1 480         conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_334 (Activation)     (None, None, None, 1 0           batch_normalization_334[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, None, None, 1 208896      block17_13_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, None, None, 1 215040      activation_334[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_332 (BatchN (None, None, None, 1 576         conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_335 (BatchN (None, None, None, 1 576         conv2d_335[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_332 (Activation)     (None, None, None, 1 0           batch_normalization_332[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_335 (Activation)     (None, None, None, 1 0           batch_normalization_335[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_mixed (Concatenate)  (None, None, None, 3 0           activation_332[0][0]             \n",
            "                                                                 activation_335[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_conv (Conv2D)        (None, None, None, 1 418880      block17_14_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_14 (Lambda)             (None, None, None, 1 0           block17_13_ac[0][0]              \n",
            "                                                                 block17_14_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_14_ac (Activation)      (None, None, None, 1 0           block17_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_337 (Conv2D)             (None, None, None, 1 139264      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_337 (BatchN (None, None, None, 1 384         conv2d_337[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_337 (Activation)     (None, None, None, 1 0           batch_normalization_337[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_338 (Conv2D)             (None, None, None, 1 143360      activation_337[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_338 (BatchN (None, None, None, 1 480         conv2d_338[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_338 (Activation)     (None, None, None, 1 0           batch_normalization_338[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_336 (Conv2D)             (None, None, None, 1 208896      block17_14_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_339 (Conv2D)             (None, None, None, 1 215040      activation_338[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_336 (BatchN (None, None, None, 1 576         conv2d_336[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_339 (BatchN (None, None, None, 1 576         conv2d_339[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_336 (Activation)     (None, None, None, 1 0           batch_normalization_336[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_339 (Activation)     (None, None, None, 1 0           batch_normalization_339[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_mixed (Concatenate)  (None, None, None, 3 0           activation_336[0][0]             \n",
            "                                                                 activation_339[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_conv (Conv2D)        (None, None, None, 1 418880      block17_15_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_15 (Lambda)             (None, None, None, 1 0           block17_14_ac[0][0]              \n",
            "                                                                 block17_15_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_15_ac (Activation)      (None, None, None, 1 0           block17_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_341 (Conv2D)             (None, None, None, 1 139264      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_341 (BatchN (None, None, None, 1 384         conv2d_341[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_341 (Activation)     (None, None, None, 1 0           batch_normalization_341[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_342 (Conv2D)             (None, None, None, 1 143360      activation_341[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_342 (BatchN (None, None, None, 1 480         conv2d_342[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_342 (Activation)     (None, None, None, 1 0           batch_normalization_342[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_340 (Conv2D)             (None, None, None, 1 208896      block17_15_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_343 (Conv2D)             (None, None, None, 1 215040      activation_342[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_340 (BatchN (None, None, None, 1 576         conv2d_340[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_343 (BatchN (None, None, None, 1 576         conv2d_343[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_340 (Activation)     (None, None, None, 1 0           batch_normalization_340[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_343 (Activation)     (None, None, None, 1 0           batch_normalization_343[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_mixed (Concatenate)  (None, None, None, 3 0           activation_340[0][0]             \n",
            "                                                                 activation_343[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_conv (Conv2D)        (None, None, None, 1 418880      block17_16_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_16 (Lambda)             (None, None, None, 1 0           block17_15_ac[0][0]              \n",
            "                                                                 block17_16_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_16_ac (Activation)      (None, None, None, 1 0           block17_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_345 (Conv2D)             (None, None, None, 1 139264      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_345 (BatchN (None, None, None, 1 384         conv2d_345[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_345 (Activation)     (None, None, None, 1 0           batch_normalization_345[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_346 (Conv2D)             (None, None, None, 1 143360      activation_345[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_346 (BatchN (None, None, None, 1 480         conv2d_346[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_346 (Activation)     (None, None, None, 1 0           batch_normalization_346[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_344 (Conv2D)             (None, None, None, 1 208896      block17_16_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_347 (Conv2D)             (None, None, None, 1 215040      activation_346[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_344 (BatchN (None, None, None, 1 576         conv2d_344[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_347 (BatchN (None, None, None, 1 576         conv2d_347[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_344 (Activation)     (None, None, None, 1 0           batch_normalization_344[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_347 (Activation)     (None, None, None, 1 0           batch_normalization_347[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_mixed (Concatenate)  (None, None, None, 3 0           activation_344[0][0]             \n",
            "                                                                 activation_347[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_conv (Conv2D)        (None, None, None, 1 418880      block17_17_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_17 (Lambda)             (None, None, None, 1 0           block17_16_ac[0][0]              \n",
            "                                                                 block17_17_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_17_ac (Activation)      (None, None, None, 1 0           block17_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_349 (Conv2D)             (None, None, None, 1 139264      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_349 (BatchN (None, None, None, 1 384         conv2d_349[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_349 (Activation)     (None, None, None, 1 0           batch_normalization_349[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_350 (Conv2D)             (None, None, None, 1 143360      activation_349[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_350 (BatchN (None, None, None, 1 480         conv2d_350[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_350 (Activation)     (None, None, None, 1 0           batch_normalization_350[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_348 (Conv2D)             (None, None, None, 1 208896      block17_17_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_351 (Conv2D)             (None, None, None, 1 215040      activation_350[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_348 (BatchN (None, None, None, 1 576         conv2d_348[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_351 (BatchN (None, None, None, 1 576         conv2d_351[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_348 (Activation)     (None, None, None, 1 0           batch_normalization_348[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_351 (Activation)     (None, None, None, 1 0           batch_normalization_351[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_mixed (Concatenate)  (None, None, None, 3 0           activation_348[0][0]             \n",
            "                                                                 activation_351[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_conv (Conv2D)        (None, None, None, 1 418880      block17_18_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_18 (Lambda)             (None, None, None, 1 0           block17_17_ac[0][0]              \n",
            "                                                                 block17_18_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_18_ac (Activation)      (None, None, None, 1 0           block17_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_353 (Conv2D)             (None, None, None, 1 139264      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_353 (BatchN (None, None, None, 1 384         conv2d_353[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_353 (Activation)     (None, None, None, 1 0           batch_normalization_353[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_354 (Conv2D)             (None, None, None, 1 143360      activation_353[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_354 (BatchN (None, None, None, 1 480         conv2d_354[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_354 (Activation)     (None, None, None, 1 0           batch_normalization_354[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_352 (Conv2D)             (None, None, None, 1 208896      block17_18_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_355 (Conv2D)             (None, None, None, 1 215040      activation_354[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_352 (BatchN (None, None, None, 1 576         conv2d_352[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_355 (BatchN (None, None, None, 1 576         conv2d_355[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_352 (Activation)     (None, None, None, 1 0           batch_normalization_352[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_355 (Activation)     (None, None, None, 1 0           batch_normalization_355[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_mixed (Concatenate)  (None, None, None, 3 0           activation_352[0][0]             \n",
            "                                                                 activation_355[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_conv (Conv2D)        (None, None, None, 1 418880      block17_19_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_19 (Lambda)             (None, None, None, 1 0           block17_18_ac[0][0]              \n",
            "                                                                 block17_19_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_19_ac (Activation)      (None, None, None, 1 0           block17_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_357 (Conv2D)             (None, None, None, 1 139264      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_357 (BatchN (None, None, None, 1 384         conv2d_357[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_357 (Activation)     (None, None, None, 1 0           batch_normalization_357[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_358 (Conv2D)             (None, None, None, 1 143360      activation_357[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_358 (BatchN (None, None, None, 1 480         conv2d_358[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_358 (Activation)     (None, None, None, 1 0           batch_normalization_358[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_356 (Conv2D)             (None, None, None, 1 208896      block17_19_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_359 (Conv2D)             (None, None, None, 1 215040      activation_358[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_356 (BatchN (None, None, None, 1 576         conv2d_356[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_359 (BatchN (None, None, None, 1 576         conv2d_359[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_356 (Activation)     (None, None, None, 1 0           batch_normalization_356[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_359 (Activation)     (None, None, None, 1 0           batch_normalization_359[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_mixed (Concatenate)  (None, None, None, 3 0           activation_356[0][0]             \n",
            "                                                                 activation_359[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_conv (Conv2D)        (None, None, None, 1 418880      block17_20_mixed[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "block17_20 (Lambda)             (None, None, None, 1 0           block17_19_ac[0][0]              \n",
            "                                                                 block17_20_conv[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block17_20_ac (Activation)      (None, None, None, 1 0           block17_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_364 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_364 (BatchN (None, None, None, 2 768         conv2d_364[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_364 (Activation)     (None, None, None, 2 0           batch_normalization_364[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_360 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_362 (Conv2D)             (None, None, None, 2 278528      block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_365 (Conv2D)             (None, None, None, 2 663552      activation_364[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_360 (BatchN (None, None, None, 2 768         conv2d_360[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_362 (BatchN (None, None, None, 2 768         conv2d_362[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_365 (BatchN (None, None, None, 2 864         conv2d_365[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_360 (Activation)     (None, None, None, 2 0           batch_normalization_360[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_362 (Activation)     (None, None, None, 2 0           batch_normalization_362[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_365 (Activation)     (None, None, None, 2 0           batch_normalization_365[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_361 (Conv2D)             (None, None, None, 3 884736      activation_360[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_363 (Conv2D)             (None, None, None, 2 663552      activation_362[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_366 (Conv2D)             (None, None, None, 3 829440      activation_365[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_361 (BatchN (None, None, None, 3 1152        conv2d_361[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_363 (BatchN (None, None, None, 2 864         conv2d_363[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_366 (BatchN (None, None, None, 3 960         conv2d_366[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_361 (Activation)     (None, None, None, 3 0           batch_normalization_361[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_363 (Activation)     (None, None, None, 2 0           batch_normalization_363[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_366 (Activation)     (None, None, None, 3 0           batch_normalization_366[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2D)  (None, None, None, 1 0           block17_20_ac[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "mixed_7a (Concatenate)          (None, None, None, 2 0           activation_361[0][0]             \n",
            "                                                                 activation_363[0][0]             \n",
            "                                                                 activation_366[0][0]             \n",
            "                                                                 max_pooling2d_8[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_368 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_368 (BatchN (None, None, None, 1 576         conv2d_368[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_368 (Activation)     (None, None, None, 1 0           batch_normalization_368[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_369 (Conv2D)             (None, None, None, 2 129024      activation_368[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_369 (BatchN (None, None, None, 2 672         conv2d_369[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_369 (Activation)     (None, None, None, 2 0           batch_normalization_369[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_367 (Conv2D)             (None, None, None, 1 399360      mixed_7a[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_370 (Conv2D)             (None, None, None, 2 172032      activation_369[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_367 (BatchN (None, None, None, 1 576         conv2d_367[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_370 (BatchN (None, None, None, 2 768         conv2d_370[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_367 (Activation)     (None, None, None, 1 0           batch_normalization_367[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_370 (Activation)     (None, None, None, 2 0           batch_normalization_370[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_mixed (Concatenate)    (None, None, None, 4 0           activation_367[0][0]             \n",
            "                                                                 activation_370[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_conv (Conv2D)          (None, None, None, 2 933920      block8_1_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_1 (Lambda)               (None, None, None, 2 0           mixed_7a[0][0]                   \n",
            "                                                                 block8_1_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_1_ac (Activation)        (None, None, None, 2 0           block8_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_372 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_372 (BatchN (None, None, None, 1 576         conv2d_372[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_372 (Activation)     (None, None, None, 1 0           batch_normalization_372[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_373 (Conv2D)             (None, None, None, 2 129024      activation_372[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_373 (BatchN (None, None, None, 2 672         conv2d_373[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_373 (Activation)     (None, None, None, 2 0           batch_normalization_373[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_371 (Conv2D)             (None, None, None, 1 399360      block8_1_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_374 (Conv2D)             (None, None, None, 2 172032      activation_373[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_371 (BatchN (None, None, None, 1 576         conv2d_371[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_374 (BatchN (None, None, None, 2 768         conv2d_374[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_371 (Activation)     (None, None, None, 1 0           batch_normalization_371[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_374 (Activation)     (None, None, None, 2 0           batch_normalization_374[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_mixed (Concatenate)    (None, None, None, 4 0           activation_371[0][0]             \n",
            "                                                                 activation_374[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_conv (Conv2D)          (None, None, None, 2 933920      block8_2_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_2 (Lambda)               (None, None, None, 2 0           block8_1_ac[0][0]                \n",
            "                                                                 block8_2_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_2_ac (Activation)        (None, None, None, 2 0           block8_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_376 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_376 (BatchN (None, None, None, 1 576         conv2d_376[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_376 (Activation)     (None, None, None, 1 0           batch_normalization_376[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_377 (Conv2D)             (None, None, None, 2 129024      activation_376[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_377 (BatchN (None, None, None, 2 672         conv2d_377[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_377 (Activation)     (None, None, None, 2 0           batch_normalization_377[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_375 (Conv2D)             (None, None, None, 1 399360      block8_2_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_378 (Conv2D)             (None, None, None, 2 172032      activation_377[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_375 (BatchN (None, None, None, 1 576         conv2d_375[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_378 (BatchN (None, None, None, 2 768         conv2d_378[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_375 (Activation)     (None, None, None, 1 0           batch_normalization_375[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_378 (Activation)     (None, None, None, 2 0           batch_normalization_378[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_mixed (Concatenate)    (None, None, None, 4 0           activation_375[0][0]             \n",
            "                                                                 activation_378[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_conv (Conv2D)          (None, None, None, 2 933920      block8_3_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_3 (Lambda)               (None, None, None, 2 0           block8_2_ac[0][0]                \n",
            "                                                                 block8_3_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_3_ac (Activation)        (None, None, None, 2 0           block8_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_380 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_380 (BatchN (None, None, None, 1 576         conv2d_380[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_380 (Activation)     (None, None, None, 1 0           batch_normalization_380[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_381 (Conv2D)             (None, None, None, 2 129024      activation_380[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_381 (BatchN (None, None, None, 2 672         conv2d_381[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_381 (Activation)     (None, None, None, 2 0           batch_normalization_381[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_379 (Conv2D)             (None, None, None, 1 399360      block8_3_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_382 (Conv2D)             (None, None, None, 2 172032      activation_381[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_379 (BatchN (None, None, None, 1 576         conv2d_379[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_382 (BatchN (None, None, None, 2 768         conv2d_382[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_379 (Activation)     (None, None, None, 1 0           batch_normalization_379[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_382 (Activation)     (None, None, None, 2 0           batch_normalization_382[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_mixed (Concatenate)    (None, None, None, 4 0           activation_379[0][0]             \n",
            "                                                                 activation_382[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_conv (Conv2D)          (None, None, None, 2 933920      block8_4_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_4 (Lambda)               (None, None, None, 2 0           block8_3_ac[0][0]                \n",
            "                                                                 block8_4_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_4_ac (Activation)        (None, None, None, 2 0           block8_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_384 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_384 (BatchN (None, None, None, 1 576         conv2d_384[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_384 (Activation)     (None, None, None, 1 0           batch_normalization_384[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_385 (Conv2D)             (None, None, None, 2 129024      activation_384[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_385 (BatchN (None, None, None, 2 672         conv2d_385[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_385 (Activation)     (None, None, None, 2 0           batch_normalization_385[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_383 (Conv2D)             (None, None, None, 1 399360      block8_4_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_386 (Conv2D)             (None, None, None, 2 172032      activation_385[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_383 (BatchN (None, None, None, 1 576         conv2d_383[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_386 (BatchN (None, None, None, 2 768         conv2d_386[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_383 (Activation)     (None, None, None, 1 0           batch_normalization_383[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_386 (Activation)     (None, None, None, 2 0           batch_normalization_386[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_mixed (Concatenate)    (None, None, None, 4 0           activation_383[0][0]             \n",
            "                                                                 activation_386[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_conv (Conv2D)          (None, None, None, 2 933920      block8_5_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_5 (Lambda)               (None, None, None, 2 0           block8_4_ac[0][0]                \n",
            "                                                                 block8_5_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_5_ac (Activation)        (None, None, None, 2 0           block8_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_388 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_388 (BatchN (None, None, None, 1 576         conv2d_388[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_388 (Activation)     (None, None, None, 1 0           batch_normalization_388[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_389 (Conv2D)             (None, None, None, 2 129024      activation_388[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_389 (BatchN (None, None, None, 2 672         conv2d_389[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_389 (Activation)     (None, None, None, 2 0           batch_normalization_389[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_387 (Conv2D)             (None, None, None, 1 399360      block8_5_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_390 (Conv2D)             (None, None, None, 2 172032      activation_389[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_387 (BatchN (None, None, None, 1 576         conv2d_387[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_390 (BatchN (None, None, None, 2 768         conv2d_390[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_387 (Activation)     (None, None, None, 1 0           batch_normalization_387[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_390 (Activation)     (None, None, None, 2 0           batch_normalization_390[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_mixed (Concatenate)    (None, None, None, 4 0           activation_387[0][0]             \n",
            "                                                                 activation_390[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_conv (Conv2D)          (None, None, None, 2 933920      block8_6_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_6 (Lambda)               (None, None, None, 2 0           block8_5_ac[0][0]                \n",
            "                                                                 block8_6_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_6_ac (Activation)        (None, None, None, 2 0           block8_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_392 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_392 (BatchN (None, None, None, 1 576         conv2d_392[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_392 (Activation)     (None, None, None, 1 0           batch_normalization_392[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_393 (Conv2D)             (None, None, None, 2 129024      activation_392[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_393 (BatchN (None, None, None, 2 672         conv2d_393[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_393 (Activation)     (None, None, None, 2 0           batch_normalization_393[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_391 (Conv2D)             (None, None, None, 1 399360      block8_6_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_394 (Conv2D)             (None, None, None, 2 172032      activation_393[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_391 (BatchN (None, None, None, 1 576         conv2d_391[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_394 (BatchN (None, None, None, 2 768         conv2d_394[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_391 (Activation)     (None, None, None, 1 0           batch_normalization_391[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_394 (Activation)     (None, None, None, 2 0           batch_normalization_394[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_mixed (Concatenate)    (None, None, None, 4 0           activation_391[0][0]             \n",
            "                                                                 activation_394[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_conv (Conv2D)          (None, None, None, 2 933920      block8_7_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_7 (Lambda)               (None, None, None, 2 0           block8_6_ac[0][0]                \n",
            "                                                                 block8_7_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_7_ac (Activation)        (None, None, None, 2 0           block8_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_396 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_396 (BatchN (None, None, None, 1 576         conv2d_396[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_396 (Activation)     (None, None, None, 1 0           batch_normalization_396[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_397 (Conv2D)             (None, None, None, 2 129024      activation_396[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_397 (BatchN (None, None, None, 2 672         conv2d_397[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_397 (Activation)     (None, None, None, 2 0           batch_normalization_397[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_395 (Conv2D)             (None, None, None, 1 399360      block8_7_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_398 (Conv2D)             (None, None, None, 2 172032      activation_397[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_395 (BatchN (None, None, None, 1 576         conv2d_395[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_398 (BatchN (None, None, None, 2 768         conv2d_398[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_395 (Activation)     (None, None, None, 1 0           batch_normalization_395[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_398 (Activation)     (None, None, None, 2 0           batch_normalization_398[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_mixed (Concatenate)    (None, None, None, 4 0           activation_395[0][0]             \n",
            "                                                                 activation_398[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_conv (Conv2D)          (None, None, None, 2 933920      block8_8_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_8 (Lambda)               (None, None, None, 2 0           block8_7_ac[0][0]                \n",
            "                                                                 block8_8_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_8_ac (Activation)        (None, None, None, 2 0           block8_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_400 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_400 (BatchN (None, None, None, 1 576         conv2d_400[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_400 (Activation)     (None, None, None, 1 0           batch_normalization_400[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_401 (Conv2D)             (None, None, None, 2 129024      activation_400[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_401 (BatchN (None, None, None, 2 672         conv2d_401[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_401 (Activation)     (None, None, None, 2 0           batch_normalization_401[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_399 (Conv2D)             (None, None, None, 1 399360      block8_8_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_402 (Conv2D)             (None, None, None, 2 172032      activation_401[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_399 (BatchN (None, None, None, 1 576         conv2d_399[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_402 (BatchN (None, None, None, 2 768         conv2d_402[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_399 (Activation)     (None, None, None, 1 0           batch_normalization_399[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_402 (Activation)     (None, None, None, 2 0           batch_normalization_402[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_mixed (Concatenate)    (None, None, None, 4 0           activation_399[0][0]             \n",
            "                                                                 activation_402[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_conv (Conv2D)          (None, None, None, 2 933920      block8_9_mixed[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_9 (Lambda)               (None, None, None, 2 0           block8_8_ac[0][0]                \n",
            "                                                                 block8_9_conv[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "block8_9_ac (Activation)        (None, None, None, 2 0           block8_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_404 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_404 (BatchN (None, None, None, 1 576         conv2d_404[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_404 (Activation)     (None, None, None, 1 0           batch_normalization_404[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_405 (Conv2D)             (None, None, None, 2 129024      activation_404[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_405 (BatchN (None, None, None, 2 672         conv2d_405[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_405 (Activation)     (None, None, None, 2 0           batch_normalization_405[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_403 (Conv2D)             (None, None, None, 1 399360      block8_9_ac[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_406 (Conv2D)             (None, None, None, 2 172032      activation_405[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_403 (BatchN (None, None, None, 1 576         conv2d_403[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_406 (BatchN (None, None, None, 2 768         conv2d_406[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_403 (Activation)     (None, None, None, 1 0           batch_normalization_403[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_406 (Activation)     (None, None, None, 2 0           batch_normalization_406[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_mixed (Concatenate)   (None, None, None, 4 0           activation_403[0][0]             \n",
            "                                                                 activation_406[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "block8_10_conv (Conv2D)         (None, None, None, 2 933920      block8_10_mixed[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "block8_10 (Lambda)              (None, None, None, 2 0           block8_9_ac[0][0]                \n",
            "                                                                 block8_10_conv[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b (Conv2D)                (None, None, None, 1 3194880     block8_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_bn (BatchNormalization) (None, None, None, 1 4608        conv_7b[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv_7b_ac (Activation)         (None, None, None, 1 0           conv_7b_bn[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gloablDropout (Dropout)         (None, None, None, 1 0           conv_7b_ac[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "gloabl_batchNormalization (Batc (None, None, None, 1 6144        gloablDropout[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "convAttentionLayer_0 (Conv2D)   (None, None, None, 2 393472      gloabl_batchNormalization[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "attentionDropout_0 (Dropout)    (None, None, None, 2 0           convAttentionLayer_0[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "convAttentionLayer_1 (Conv2D)   (None, None, None, 2 65792       attentionDropout_0[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attentionDropout_1 (Dropout)    (None, None, None, 2 0           convAttentionLayer_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "convAttentionLayer_2 (Conv2D)   (None, None, None, 2 65792       attentionDropout_1[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attentionDropout_2 (Dropout)    (None, None, None, 2 0           convAttentionLayer_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "convAttentionLayer_3 (Conv2D)   (None, None, None, 2 65792       attentionDropout_2[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attentionDropout_3 (Dropout)    (None, None, None, 2 0           convAttentionLayer_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "convAttentionLayer_1D (Conv2D)  (None, None, None, 1 257         attentionDropout_3[0][0]         \n",
            "__________________________________________________________________________________________________\n",
            "attentionDropout_1D (Dropout)   (None, None, None, 1 0           convAttentionLayer_1D[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "upConv2d (Conv2D)               (None, None, None, 1 1536        attentionDropout_1D[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "multiply_maskFeature (Multiply) (None, None, None, 1 0           upConv2d[0][0]                   \n",
            "                                                                 gloabl_batchNormalization[0][0]  \n",
            "__________________________________________________________________________________________________\n",
            "attentionGlobalAveragePooling_f (None, 1536)         0           multiply_maskFeature[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "attentionGlobalAveragePooling_m (None, 1536)         0           upConv2d[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "rescaleGlobalAeragePooling (Lam (None, 1536)         0           attentionGlobalAveragePooling_fea\n",
            "                                                                 attentionGlobalAveragePooling_mas\n",
            "__________________________________________________________________________________________________\n",
            "batchNormalization_fc1 (BatchNo (None, 1536)         6144        rescaleGlobalAeragePooling[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_fc1 (Dense)               (None, 4096)         6295552     batchNormalization_fc1[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_fc13 (Dropout)          (None, 4096)         0           dense_fc1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "prediction (Dense)              (None, 5)            20485       dropout_fc13[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 61,257,702\n",
            "Trainable params: 60,205,366\n",
            "Non-trainable params: 1,052,336\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/100\n",
            "2000/2000 [==============================] - 5434s 3s/step - loss: 4.7335 - acc: 0.7742 - val_loss: 4.0963 - val_acc: 0.7437\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.09633, saving model to ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5\n",
            "Epoch 2/100\n",
            "2000/2000 [==============================] - 5348s 3s/step - loss: 1.0913 - acc: 0.8138 - val_loss: 3.5124 - val_acc: 0.7325\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.09633 to 3.51242, saving model to ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5\n",
            "Epoch 3/100\n",
            "2000/2000 [==============================] - 5356s 3s/step - loss: 0.7354 - acc: 0.8362 - val_loss: 3.4237 - val_acc: 0.7281\n",
            "\n",
            "Epoch 00003: val_loss improved from 3.51242 to 3.42373, saving model to ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5\n",
            "Epoch 4/100\n",
            "1999/2000 [============================>.] - ETA: 1s - loss: 0.5349 - acc: 0.8643"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FyWbJoGGbqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5 /content/gdrive/My\\ Drive/Transfer_learn_299_299_EFIGI.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY8IL-JMEsKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}