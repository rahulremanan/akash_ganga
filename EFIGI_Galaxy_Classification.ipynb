{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EFIGI_Galaxy_Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPEdA0Hb4vOf",
        "colab_type": "text"
      },
      "source": [
        "# Galaxy Calssification using  the EFIGI reference dataset \n",
        "\n",
        "## Author: Avi Vajpeyi, Dr. Rahul Remanan \n",
        "### This project was conceived as part of the 2018 Summer Internship, [@Moad Computer](https://www.moad.computer)\n",
        "\n",
        "### [EFIGI data](https://www.astromatic.net/projects/efigi)\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/rahulremanan/akash_ganga/blob/master/EFIGI_Galaxy_Classification.ipynb)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fV17Frt2riXQ",
        "colab_type": "text"
      },
      "source": [
        "## Setting notebook behavior"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJ6dPot4HRTa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "download_raw_data = False #Set True to download the raw data from https://www.astromatic.net/download/efigi/\n",
        "setup = True #Set this flag to True to install all the dependencies and load data from the cloud object storage\n",
        "upload_data = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xr-oj4HKEwpW",
        "colab_type": "text"
      },
      "source": [
        "## Copy preprocessed data to Drive\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8zio0_ian14",
        "colab_type": "text"
      },
      "source": [
        "## Connect Google Drive to this session"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Zzh0e9qjDCJ",
        "colab_type": "text"
      },
      "source": [
        "This code adds ./drive/ (your google drive home folder) to the current session. You cannot cd into this but can access the files on google drive this way.\n",
        "\n",
        "Code obtained from [Google Colab Free GPU Tutorial](https://medium.com/deep-learning-turkey/google-colab-free-gpu-tutorial-e113627b9f5d)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2uIr4PHhl2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if setup:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh9-Pk3T0tnO",
        "colab_type": "text"
      },
      "source": [
        "### Copy and unzip sorted data from drive to local"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PILw4g1D2Lkd",
        "colab_type": "text"
      },
      "source": [
        "Data accessible from ./data/train and ./data/validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bp4EJ2vj1D1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not download_raw_data and setup:\n",
        "  ! cp /content/gdrive/My\\ Drive/sorted_data_EFIGI.zip ./\n",
        "! mkdir ./drive\n",
        "! mkdir ./drive/EFIGI_Galaxy_Classification/\n",
        "! mkdir ./drive/EFIGI_Galaxy_Classification/output/\n",
        "! mkdir ./drive/EFIGI_Galaxy_Classification/output/checkpoint\n",
        "! cp /content/gdrive/My\\ Drive/Transfer_learn_299_299_EFIGI.h5 ./drive/EFIGI_Galaxy_Classification/output//checkpoint/\n",
        "! mv ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_EFIGI.h5 ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5\n",
        "if setup:\n",
        "  ! unzip -q sorted_data_EFIGI.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbUR2n9suuLJ",
        "colab_type": "text"
      },
      "source": [
        "## Define python function to run linux commands"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jOBuQwIbvEE3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import subprocess\n",
        " \n",
        "def execute_in_shell(command=None,\n",
        "                     verbose=False):\n",
        "    \"\"\"\n",
        "    This is a function that executes shell scripts from within python.\n",
        "\n",
        "    Example usage:\n",
        "    execute_in_shell(command = ['ls ./some/folder/',\n",
        "                                'ls ./some/folder/  -1 | wc -l'],\n",
        "                     verbose = True )\n",
        "\n",
        "    This command returns dictionary with elements: Output and Error.\n",
        "\n",
        "    Output records the console output,\n",
        "    Error records the console error messages.\n",
        "\n",
        "    :param command: takes a list of shell commands\n",
        "    :param verbose: takes a boolean value to set verbose level\n",
        "    :return: Dictionary with two elements Output and Error\n",
        "    \"\"\"\n",
        "\n",
        "    error = []\n",
        "    output = []\n",
        "\n",
        "    if isinstance(command, list):\n",
        "        for i in range(len(command)):\n",
        "            try:\n",
        "                process = subprocess.Popen(command[i], shell=True,\n",
        "                                           stdout=subprocess.PIPE)\n",
        "                process.wait()\n",
        "                out, err = process.communicate()\n",
        "                error.append(err)\n",
        "                output.append(out)\n",
        "                if verbose:\n",
        "                    print(\n",
        "                        'Success running shell command: {}'.format(command[i]))\n",
        "            except Exception as e:\n",
        "                print('Failed running shell command: {}'.format(command[i]))\n",
        "                if verbose:\n",
        "                    print(type(e))\n",
        "                    print(e.args)\n",
        "                    print(e)\n",
        "\n",
        "    else:\n",
        "        print('The argument command takes a list input ...')\n",
        "    return {'Output': output, 'Error': error}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq8A4j1B5S59",
        "colab_type": "text"
      },
      "source": [
        "## Download and sort data\n",
        "Currently only using coloured processed images rather than the sperate images that the final image is composed of. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-cu1tAhVhQS",
        "colab_type": "text"
      },
      "source": [
        "### Download data\n",
        "The EFIGI dataset info we are using is in 6 separate compressed archives (gzipped\n",
        "tar format):\n",
        "- efigi_tables-1.6.tgz: 6 ASCII tables, including morphological information\n",
        "- efigi_png_gri-1.6.tgz: 4458 PNG images in the SDSS g,r and i bands\n",
        "- efigi_ima_u-1.6.tgz: 4458 galaxy images in the SDSS u-band (FITS format)\n",
        "- efigi_ima_g-1.6.tgz: 4458 galaxy images in the SDSS g-band (FITS format)\n",
        "- efigi_ima_r-1.6.tgz: 4458 galaxy images in the SDSS r-band (FITS format)\n",
        "- efigi_ima_i-1.6.tgz: 4458 galaxy images in the SDSS i-band (FITS format)\n",
        "- efigi_ima_z-1.6.tgz: 4458 galaxy images in the SDSS z-band (FITS format)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2Q_47OX5aeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if download_raw_data:\n",
        "  ! mkdir ./data\n",
        "  ! mkdir ./data/raw\n",
        "\n",
        " \n",
        "  ! wget  -O ./data/raw/efigi-1.6.tgz \"https://www.astromatic.net/download/efigi/efigi_tables-1.6.2.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_png_gri-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_u_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_u-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_g_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_g-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_r_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_r-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_i_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_i-1.6.tgz\"\n",
        "  ! wget  -O ./data/raw/efigi_z_pics.tgz \"https://www.astromatic.net/download/efigi/efigi_ima_z-1.6.tgz\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ncwhv7gGx-7P",
        "colab_type": "text"
      },
      "source": [
        "### Zip and move raw files to the object drive\n",
        "DO ONLY ONCE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgdwwES6xwIE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if upload_data:\n",
        "  ! zip -q -r raw_data_EFIGI.zip ./data/raw/\n",
        "  ! cp raw_data_EFIGI.zip /content/gdrive//My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9qyTgep-nXS",
        "colab_type": "text"
      },
      "source": [
        "### Unpack data from tgz\n",
        "Data stored in\n",
        "\n",
        "* Tables:  ` ./data/raw/efigi-1.6/ `\n",
        "* Colored Images:   ` ./data/raw/efigi-1.6/png ` \n",
        "* FITS: `/efigi-1.6/ima_g,  ima_i, ima_u, ima_z`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDtOzw_Lv-Wp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if download_raw_data:\n",
        "  import glob\n",
        "  tgz_files = glob.glob(\"./data/raw/*tgz\")\n",
        "  for tgz_file in tgz_files:\n",
        "    command=[\"tar xzf \"+tgz_file+\" -C ./data/raw/\", \"rm \"+tgz_file]\n",
        "    execute_in_shell(command, verbose=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LqW2qQLUjnO",
        "colab_type": "text"
      },
      "source": [
        "### Convert fits to png"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z5Hha_mS3_v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.pyplot as plt\n",
        "from astropy.utils.data import get_pkg_data_filename\n",
        "from astropy.io import fits\n",
        "import numpy as np\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "\n",
        "def fits_to_png(fits_fn):\n",
        "    # Generally the image information is located in the Primary HDU (ext 0)\n",
        "    # read the image data from this first extension using the keyword argument\n",
        "    data = fits.getdata(fits_fn, ext=0)\n",
        "\n",
        "    sizes = np.shape(data)\n",
        "    height = float(sizes[0])\n",
        "    width = float(sizes[1])\n",
        "\n",
        "    fig = plt.figure()\n",
        "    fig.set_size_inches(width / height, 1, forward=False)\n",
        "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
        "    ax.set_axis_off()\n",
        "    fig.add_axes(ax)\n",
        "\n",
        "    ax.imshow(data, cmap=\"binary\")\n",
        "\n",
        "    # createing png filename from fits filename\n",
        "    png_fn = fits_fn.split(\".fits\")[0] + \".png\"\n",
        "\n",
        "\n",
        "    plt.savefig(png_fn, dpi=height)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def fits_folder_to_png(dir, verbose):\n",
        "\n",
        "    fits_files = glob.glob( dir+\"*.fits\")\n",
        "    num_files = len(fits_files)\n",
        "    status_flag = num_files * 0.1\n",
        "\n",
        "    for i in range(0, num_files):\n",
        "        fits_to_png(fits_files[i])\n",
        "\n",
        "        if verbose and i > status_flag:\n",
        "            status_flag += num_files * 0.1\n",
        "            p_done = (i * 100// num_files) \n",
        "            print(str(p_done)+\"% processed\")\n",
        "\n",
        "def delete_fits_from_folder(dir):\n",
        "    fits_files = glob.glob(dir+\"*.fits\")\n",
        "    for f in fits_files:\n",
        "      os.remove(f)\n",
        "\n",
        "\n",
        "def make_movie_from_png(video_name, dir):\n",
        "\n",
        "    images = glob.glob(dir + \"*.png\")\n",
        "    frame = cv2.imread(images[0])\n",
        "    height, width, layers = frame.shape\n",
        "\n",
        "    video = cv2.VideoWriter(video_name, -1, 25, (width, height))\n",
        "\n",
        "    for image in images:\n",
        "        video.write(cv2.imread(image))\n",
        "\n",
        "    cv2.destroyAllWindows()\n",
        "    video.release()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLkULVfzMzna",
        "colab_type": "text"
      },
      "source": [
        "Execute following to convert the images into pngs.\n",
        "This can take a while...Can be timed out and if you are then run again, itll pick up where it left off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oK3zMZlc0JmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import os\n",
        "import gc\n",
        "\n",
        "if setup:\n",
        "  FITS_folders = [\"ima_g\", \"ima_i\",\"ima_u\",\"ima_z\",\"ima_r\"]\n",
        "  for fits_folder in FITS_folders:\n",
        "    dir = \"./data/raw/efigi-1.6/\"+fits_folder+\"/\"\n",
        "    print(\"Processing \"+dir)\n",
        "    fits_folder_to_png(dir, verbose=True)\n",
        "    delete_fits_from_folder(dir)\n",
        "    gc.collect()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRDdIwgRMrjG",
        "colab_type": "text"
      },
      "source": [
        "### Make Galaxy Type Enum "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5u3oX1sOMqyV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from enum import Enum, auto, unique\n",
        "@unique\n",
        "class T(Enum):\n",
        "  ''' Enum to store the different types of galaxies\n",
        "  '''\n",
        "  ELLIPTICAL = auto()\n",
        "  LENTICULAR = auto()\n",
        "  SPIRAL = auto()\n",
        "  IRREGULAR = auto()\n",
        "  DWARF = auto()\n",
        "\n",
        "  def __str__(self):\n",
        "    '''To print the name of the galaxy type when enum printed\n",
        "    '''\n",
        "    return str(self.name)\n",
        "\n",
        "def check_class(t_val):\n",
        "  '''Takes the t_val attribute and returns the associated enum\n",
        "  '''\n",
        "  try:\n",
        "    t_val = int(t_val)\n",
        "  except ValueError:\n",
        "    pass  # it was a string, not an int.\n",
        "  if t_val < -3:\n",
        "    return T.ELLIPTICAL\n",
        "  elif  t_val < 0:\n",
        "    return T.LENTICULAR\n",
        "  elif t_val < 10:\n",
        "    return T.SPIRAL\n",
        "  elif t_val == 10:\n",
        "    return T.IRREGULAR\n",
        "  elif t_val == 11:\n",
        "    return T.DWARF\n",
        "  else:\n",
        "    print (\"ERROR\")\n",
        "    # raise exception\n",
        "    return null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvCeZeuWG61a",
        "colab_type": "text"
      },
      "source": [
        "### Make Organisational Folders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3DXbGaCG6Eg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "train_dir = './data/train/'\n",
        "val_dir = './data/validation'\n",
        "if setup and download_raw_data:\n",
        "  galaxy_classes = [name for name, gal_type in T.__members__.items()]\n",
        "  execute_in_shell([\"mkdir {} {}\".format(train_dir, val_dir)])\n",
        "  for galaxy_class in galaxy_classes:\n",
        "    commands =[\"mkdir {}{} {}{}\"\n",
        "               .format(train_dir, \n",
        "                       galaxy_class, \n",
        "                       val_dir, \n",
        "                       galaxy_class)]\n",
        "    execute_in_shell(commands)\n",
        "\n",
        "  print(\"Folders in {}: \".format(train_dir))\n",
        "  print (os.listdir(train_dir))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w54wmJq1B9b4",
        "colab_type": "text"
      },
      "source": [
        "### Move files from orignal folder to their classes folder\n",
        "\n",
        "The table `data/raw/efigi-1.6/EFIGI_attributes.txt` has several attributes. We need the \"PGC_name\" and \"T\" (the file name and EFIGI morphological type). Based on this, we will move the file from `./raw` to `./train/{type}`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FsTTBmN9DtjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil\n",
        "\n",
        "\n",
        "def row_generator(filepath):\n",
        "  ''' Grabs one row of the txt file if its not a comment\n",
        "  '''\n",
        "  with open(filepath) as fp:\n",
        "\n",
        "      # Skip initial comments that starts with #\n",
        "      while True:\n",
        "          row = fp.readline()\n",
        "          if not row.startswith('#'):\n",
        "              break\n",
        "\n",
        "      # Second while loop to process the rest of the file\n",
        "      while row:\n",
        "          yield (row)\n",
        "          row = fp.readline()\n",
        "\n",
        "\n",
        "\n",
        "def move_file_by_class(filename, type, image_foldername):\n",
        "  current_dir = \"data/raw/efigi-1.6/\"+image_foldername+\"/\"+filename\n",
        "  destination_dir = \"data/train/\"+ type.name + \"/\" + filename\n",
        "  shutil.move(current_dir, destination_dir)\n",
        "\n",
        "\n",
        "def move_files_according_to_txt(txt_filepath, img_folder, extension, verbose):\n",
        "  print(\"Moving files from \"+img_folder)\n",
        "\n",
        "  count = 0\n",
        "  for line in row_generator(txt_filepath):\n",
        "    attributes = line.split()\n",
        "\n",
        "    # create file name based on PGC_name\n",
        "    if extension is None:\n",
        "      image_file_name = attributes[0]+\".png\"\n",
        "    else:\n",
        "      image_file_name = attributes[0]+\"_\"+extension+\".png\"\n",
        "\n",
        "    # get type according to dataset\n",
        "    image_class = check_class(attributes[1])\n",
        "\n",
        "\n",
        "    move_file_by_class(image_file_name, image_class, img_folder)\n",
        "\n",
        "    count +=1\n",
        "    if count % 100 == 0 and verbose:\n",
        "      print (\"Image Num\"+str(count)+\": \" +image_file_name+ \" is a \" + image_class.name)\n",
        "  print(\"Done moving from \"+img_folder+ \" to data/train/\")\n",
        "\n",
        "\n",
        "\n",
        "if setup and download_raw_data:\n",
        "  image_folders = [\"png\",\"ima_g\", \"ima_i\", \"ima_u\", \"ima_z\", \"ima_r\"]\n",
        "  extensions =[None, \"g\",\"i\",\"u\",\"z\",\"r\"]\n",
        "\n",
        "  for i in range(0,len(extensions)):\n",
        "    move_files_according_to_txt(txt_filepath = \"data/raw/efigi-1.6/EFIGI_attributes.txt\",\n",
        "                                img_folder = image_folders[i], \n",
        "                                extension = extensions[i], \n",
        "                                verbose = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-A9_M1QcoeW",
        "colab_type": "text"
      },
      "source": [
        "### Shuffle some files from training folder to validation folder\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWKfOmBkCbXN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, glob, random \n",
        "if setup and download_raw_data: \n",
        "  subfolders = [f.path for f in os.scandir(train_dir) if f.is_dir()] \n",
        "\n",
        "  # For each training folder \n",
        "  for train_class_dir in subfolders:\n",
        "\n",
        "    # Get total number of files in folder\n",
        "    images = glob.glob(train_class_dir+\"/*.png\")\n",
        "    total_num = len(images)\n",
        "    print (train_class_dir +\" has \" + str(total_num)+\" images.\")\n",
        "\n",
        "    # Shuffle 20% files\n",
        "    number_of_validation = int(0.2*float(total_num)) # 20% validation\n",
        "    files_to_move = random.sample(images, number_of_validation)\n",
        "\n",
        "\n",
        "    class_name = train_class_dir.split(\"/\")[-1]\n",
        "\n",
        "    # Move 20% to the validation folder of the same class\n",
        "    for file_dir in files_to_move:\n",
        "      destination_dir = file_dir.split(\"/train/\")[0]+\"/validation/\"+file_dir.split(\"/train/\")[-1]\n",
        "      shutil.move(file_dir, destination_dir)\n",
        "\n",
        "    num_images_remaining = len(glob.glob(train_class_dir+\"/*.png\"))\n",
        "    print (\"After transfer \" + str(num_images_remaining)+\" images will remain as training data.\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lszJVNpPf4_",
        "colab_type": "text"
      },
      "source": [
        "### Remove Raw Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ti0g17tmPfcL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, shutil\n",
        "if setup and download_raw_data:\n",
        "  shutil.rmtree(\"./data/raw\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDIdQ8BQQQGo",
        "colab_type": "text"
      },
      "source": [
        "### Zip and move sorted data to drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw9p0aUSQXmH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if upload_data:\n",
        "  ! zip -q -r sorted_data_EFIGI.zip ./data\n",
        "  ! cp -v sorted_data_EFIGI.zip /content/gdrive/My\\ Drive/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFLTKb79r4AU",
        "colab_type": "text"
      },
      "source": [
        "## Train a deep convolutional neural network calssifier\n",
        "\n",
        "- Galaxy classifier using Inception-ResNet version 2.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfKo3b02shb",
        "colab_type": "text"
      },
      "source": [
        "### Imports for ML that will be needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJU5Dfq1uYh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "try:\n",
        "    import h5py\n",
        "except:\n",
        "    print ('Package h5py needed for saving model weights ...')\n",
        "    sys.exit(1)\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import tensorflow\n",
        "    import keras\n",
        "except:\n",
        "    print ('This code uses tensorflow deep-learning framework and keras api ...')\n",
        "    print ('Install tensorflow and keras to train the classifier ...')\n",
        "    sys.exit(1)\n",
        "    \n",
        "import PIL # Python Imaging Library\n",
        "from collections import defaultdict\n",
        "from keras.applications.inception_v3 import InceptionV3,    \\\n",
        "                                            preprocess_input as preprocess_input_inceptionv3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2,    \\\n",
        "                                            preprocess_input as preprocess_input_inceptionv4\n",
        "from keras.models import Model,                             \\\n",
        "                         model_from_json,                    \\\n",
        "                         load_model\n",
        "from keras.layers import Dense,                             \\\n",
        "                         GlobalAveragePooling2D,            \\\n",
        "                         Dropout,                           \\\n",
        "                         BatchNormalization,\\\n",
        "                         Concatenate\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD,                           \\\n",
        "                             RMSprop,                       \\\n",
        "                             Adagrad\n",
        "from keras.callbacks import EarlyStopping,   \\\n",
        "                            ModelCheckpoint, \\\n",
        "                            ReduceLROnPlateau\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MB6UlsJ0m30a",
        "colab_type": "text"
      },
      "source": [
        "### Fetch saved weights from Google drive storage object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4IvMMYis0kR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import glob\n",
        "\n",
        "try:\n",
        "    import h5py\n",
        "except:\n",
        "    print('Package h5py needed for saving model weights ...')\n",
        "    sys.exit(1)\n",
        "import json\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "    import tensorflow\n",
        "    import keras\n",
        "except:\n",
        "    print(\n",
        "        'This code uses tensorflow deep-learning framework and keras api ...')\n",
        "    print('Install tensorflow and keras to train the classifier ...')\n",
        "    sys.exit(1)\n",
        "\n",
        "import PIL  # Python Imaging Library\n",
        "from collections import defaultdict\n",
        "from keras.applications.inception_v3 import InceptionV3, \\\n",
        "    preprocess_input as preprocess_input_inceptionv3\n",
        "from keras.applications.inception_resnet_v2 import InceptionResNetV2, \\\n",
        "    preprocess_input as preprocess_input_inceptionv4\n",
        "from keras.models import Model, \\\n",
        "    model_from_json, \\\n",
        "    load_model\n",
        "from keras.layers import Dense, \\\n",
        "    GlobalAveragePooling2D, \\\n",
        "    Dropout, \\\n",
        "    BatchNormalization,\\\n",
        "    merge\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import SGD, \\\n",
        "    RMSprop, \\\n",
        "    Adagrad\n",
        "from keras.callbacks import EarlyStopping, \\\n",
        "    ModelCheckpoint, \\\n",
        "    ReduceLROnPlateau\n",
        "\n",
        "\n",
        "def generate_timestamp():\n",
        "    \"\"\"\n",
        "    Generates a timestring in the format year_month_day-hr_min_sec\n",
        "\n",
        "    :return: a string that holds the timestring\n",
        "    \"\"\"\n",
        "    timestring = time.strftime(\"%Y_%m_%d-%H_%M_%S\")\n",
        "    print(\"Time stamp generated: \" + timestring)\n",
        "    return timestring\n",
        "\n",
        "\n",
        "def is_valid_file(parser, arg):\n",
        "    \"\"\"\n",
        "    Checks if a file passed as an arg exists\n",
        "\n",
        "    :param parser:  an ArgumentParser object that can process command line args\n",
        "    :param arg: filename\n",
        "    :return: the filename if the file exists, otherwise null\n",
        "    \"\"\"\n",
        "    if not os.path.isfile(arg):\n",
        "        parser.error(\"The file %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def is_valid_dir(parser, arg):\n",
        "    \"\"\"\n",
        "    Checks if a dir passed as an arg exists\n",
        "\n",
        "    :param parser: an ArgumentParser object that can process command line args\n",
        "    :param arg: directory path\n",
        "    :return: the dir path if the dir exists\n",
        "    \"\"\"\n",
        "    if not os.path.isdir(arg):\n",
        "        parser.error(\"The folder %s does not exist ...\" % arg)\n",
        "    else:\n",
        "        return arg\n",
        "\n",
        "\n",
        "def string_to_bool(val):\n",
        "    \"\"\"\n",
        "    Converts yes, y, 1, t, n, 0, f, False into their appropriate bools\n",
        "\n",
        "    :param val: a string\n",
        "    :return: the associated bool (True/False) otherwise an error\n",
        "    \"\"\"\n",
        "    if val.lower() in ('yes', 'true', 't', 'y', '1', 'yeah'):\n",
        "        return True\n",
        "    elif val.lower() in ('no', 'false', 'f', 'n', '0', 'none'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Boolean value expected ...')\n",
        "\n",
        "\n",
        "def get_nb_files(directory):\n",
        "    \"\"\"\n",
        "    Gets the number of files in a directory\n",
        "\n",
        "    :param directory: the dir that we are counting the number of files in\n",
        "    :return: the count of the files in the dir (0 if the dir doesnt exist)\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory):\n",
        "        return 0\n",
        "    cnt = 0\n",
        "    for r, dirs, files in os.walk(directory):\n",
        "        for dr in dirs:\n",
        "            cnt += len(glob.glob(os.path.join(r, dr + \"/*\")))\n",
        "    return cnt\n",
        "\n",
        "\n",
        "def setup_to_transfer_learn(model, base_model, optimizer):\n",
        "    \"\"\"\n",
        "    Helps join a previous model (the base model) to new model\n",
        "\n",
        "    ???: where are base_model and model joined\n",
        "\n",
        "    :param model: the new model to be trained\n",
        "    :param base_model: the pre existing base model, already trained\n",
        "    :param optimizer: the optimizer function to train the new model\n",
        "    :return: the new model\n",
        "    \"\"\"\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "    model.compile(optimizer=optimizer,\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IdeDxdY9C8J5",
        "colab_type": "text"
      },
      "source": [
        "## Dense attention layer for the top decision layer\n",
        "\n",
        "The implementation of dense attention layer is a modified fork described [here](https://github.com/philipperemy/keras-attention-mechanism/blob/master/attention_dense.py)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVEhATJoA7LS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def add_top_layer(base_model, nb_classes):\n",
        "    \"\"\"\n",
        "    Add a fully connected convolutional neural network layer\n",
        "\n",
        "    ???: confused about x1, x2, x12, x3\n",
        "\n",
        "    :param base_model: the current model\n",
        "    :param nb_classes: the number of classes that we need to predict for\n",
        "    :return: the new model with additional CNN layer\n",
        "    \"\"\"\n",
        "\n",
        "    # create dropout layer\n",
        "    # (drops units from NN to prevent overfitting)\n",
        "    try:\n",
        "        dropout = float(args.dropout[0])\n",
        "    except:\n",
        "        dropout = DEFAULT_DROPOUT\n",
        "        print('Invalid input for dropout ...')\n",
        "\n",
        "    # choose activation function\n",
        "    try:\n",
        "        activation = str(args.activation[0]).lower()\n",
        "        print('Building model using default activation function: ' + str(activation))\n",
        "    except:\n",
        "        activation = 'relu'\n",
        "        print('Invalid input for activation function ...')\n",
        "        print(\"Choice of activation functions: hard_sigmoid, elu, linear, relu,\" \n",
        "              \"selu, sigmoid, softmax, softplus, sofsign, tanh ...\")\n",
        "        print('Building model using default activation function: relu')\n",
        "\n",
        "    bm = base_model.output\n",
        "\n",
        "    x = Dropout(dropout, name='dropout_1')(bm)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    #x = Dropout(dropout,name='dropout_2')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    \n",
        "    xattn = Dense(FC_SIZE, name='dense_attention_1',activation='softmax')(x)\n",
        "    \n",
        "    x_concat = concatenate([x, xattn], name='concatenate_1')\n",
        "    \n",
        "    xout = Dense(FC_SIZE, name='fc_dense_1', activation=activation)(x_concat)\n",
        "    xout = Dropout(dropout, name='fc_dropout_1')(xout)\n",
        "\n",
        "    predictions = Dense(nb_classes,\n",
        "                        activation='softmax',\n",
        "                        name='prediction')(xout)  # New softmax layer\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JDvlzlceB-x7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def setup_to_finetune(model, optimizer, NB_FROZEN_LAYERS):\n",
        "    \"\"\"\n",
        "    Freezes some of the bottom layers of the model to not be trained\n",
        "\n",
        "    :param model: the current ML model\n",
        "    :param optimizer: optimizer function being used for the training of the model\n",
        "    :param NB_FROZEN_LAYERS: Freeze the bottom NB_LAYERS and retrain the remaining top layers\n",
        "    :return: the updated new model with some of the bottom layers frozen\n",
        "    \"\"\"\n",
        "    for layer in model.layers[:NB_FROZEN_LAYERS]:\n",
        "        layer.trainable = False\n",
        "    for layer in model.layers[NB_FROZEN_LAYERS:]:\n",
        "        layer.trainable = True\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_model(args, name, model):\n",
        "    \"\"\"\n",
        "    Saves the\n",
        "    1) model weights in name.model\n",
        "    2) model config (the number of layers, activation funcs, etc) in name.json.\n",
        "    Both are stored in a dir specified in args.output_dir[0].\n",
        "\n",
        "    :param args: holds the saving dir in args.output_dir[0]\n",
        "    :param name: name of the saved model weights and model config\n",
        "    :param model: the model to be saved\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "    file_loc = args.output_dir[0]\n",
        "    file_pointer_str = file_loc + \"//trained_\" + timestr\n",
        "    file_pointer = os.path.join(file_pointer_str)\n",
        "    model_save_str = file_pointer + \"_weights\" + str(name) + \".model\"\n",
        "    model.save_weights(os.path.join(model_save_str))\n",
        "\n",
        "    model_json = model.to_json()  # Serialize model to JSON\n",
        "    config_save_str = file_pointer + \"_config\" + str(name) + \".json\"\n",
        "    with open(os.path.join(config_save_str), \"w\") as json_file:\n",
        "        json_file.write(model_json)\n",
        "    print(\"Saved the trained model weights to: \" +\n",
        "          str(os.path.join(file_pointer + \"_weights\" + str(name) + \".model\")))\n",
        "    print(\"Saved the trained model configuration as a json file to: \" +\n",
        "          str(os.path.join(file_pointer + \"_config\" + str(name) + \".json\")))\n",
        "\n",
        "\n",
        "def generate_labels(args):\n",
        "    \"\"\"\n",
        "    Generates labels from folder names in data/train/ and data/validation/\n",
        "    IF the labels from train and validation folders match, labels are returned\n",
        "    and a json with the lables is saved\n",
        "\n",
        "    :param args: holds the saving dir in args.output_dir[0]\n",
        "    :return: a sorted dict with the labels\n",
        "    \"\"\"\n",
        "    file_loc = args.output_dir[0]\n",
        "    file_pointer = os.path.join(file_loc + \"//trained_labels\")\n",
        "\n",
        "    data_dir = args.train_dir[0]\n",
        "    val_dir_ = args.val_dir[0]\n",
        "\n",
        "    dt = defaultdict(list)\n",
        "    dv = defaultdict(list)\n",
        "\n",
        "    for root, subdirs, files in os.walk(data_dir):\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(root, filename)\n",
        "            assert file_path.startswith(data_dir)\n",
        "            suffix = file_path[len(data_dir):]\n",
        "            suffix = suffix.lstrip(\"/\")\n",
        "            label = suffix.split(\"/\")[0]\n",
        "            dt[label].append(file_path)\n",
        "\n",
        "    for root, subdirs, files in os.walk(val_dir_):\n",
        "        for filename in files:\n",
        "            file_path = os.path.join(root, filename)\n",
        "            assert file_path.startswith(val_dir_)\n",
        "            suffix = file_path[len(val_dir_):]\n",
        "            suffix = suffix.lstrip(\"/\")\n",
        "            label = suffix.split(\"/\")[0]\n",
        "            dv[label].append(file_path)\n",
        "\n",
        "    labels = sorted(dt.keys())\n",
        "    val_labels = sorted(dv.keys())\n",
        "\n",
        "    if set(labels) == set(val_labels):\n",
        "        print(\"Training labels: \" + str(labels))\n",
        "        print(\"Validation labels: \" + str(val_labels))\n",
        "        with open(os.path.join(file_pointer + \".json\"), \"w\") as json_file:\n",
        "            json.dump(labels, json_file)\n",
        "    else:\n",
        "        print(\"Training labels: \" + str(labels))\n",
        "        print(\"Validation labels: \" + str(val_labels))\n",
        "        print(\"Mismatched training and validation data labels ...\")\n",
        "        print(\n",
        "            \"Sub-folder names do not match between training and validation \"\n",
        "            \"directories ...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    return labels\n",
        "\n",
        "\n",
        "def generate_plot(args, name, model_train):\n",
        "    \"\"\"\n",
        "    Checks if plots were made and if so, displays plots of training\n",
        "\n",
        "    :param args: holds the bool about if there were to be plots of\n",
        "    training made, in args.plot[0]\n",
        "    :param name: name of plots\n",
        "    :param model_train: the model that was trained\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "    gen_plot = args.plot[0]\n",
        "    if gen_plot == True:\n",
        "        plot_training(args, name, model_train)\n",
        "    else:\n",
        "        print(\"No training summary plots generated ...\")\n",
        "        print(\"Set: --plot True for creating training summary plots\")\n",
        "\n",
        "\n",
        "def plot_training(args, name, history):\n",
        "    \"\"\"\n",
        "    Plots the accuracy vs epoch and loss vs epoch and saves as png files\n",
        "\n",
        "    ???: actual parameter is \"model\" but formal parameter is \"history\"...\n",
        "\n",
        "    :param args: holds the outpt dir\n",
        "    :param name: the names of the plots\n",
        "    :param history: the datapoints of the training\n",
        "    :return: null\n",
        "    \"\"\"\n",
        "    output_loc = args.output_dir[0]\n",
        "\n",
        "    output_file_acc = os.path.join(output_loc +\n",
        "                                   \"//training_plot_acc_\" +\n",
        "                                   timestr + str(name) + \".png\")\n",
        "    output_file_loss = os.path.join(output_loc +\n",
        "                                    \"//training_plot_loss_\" +\n",
        "                                    timestr + str(name) + \".png\")\n",
        "    fig_acc = plt.figure()\n",
        "    plt.plot(history.history['acc'])\n",
        "    plt.plot(history.history['val_acc'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    fig_acc.savefig(output_file_acc, dpi=fig_acc.dpi)\n",
        "    print(\"Successfully created the training accuracy plot: \"\n",
        "          + str(output_file_acc))\n",
        "    plt.close()\n",
        "\n",
        "    fig_loss = plt.figure()\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    fig_loss.savefig(output_file_loss, dpi=fig_loss.dpi)\n",
        "    print(\"Successfully created the loss function plot: \"\n",
        "          + str(output_file_loss))\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def train(args):\n",
        "    \"\"\"\n",
        "    Helper function to train a model based on args\n",
        "\n",
        "    :param args: some of the arguments and possible values are\n",
        "            args.config_file = ['./model/model_efc.json']\n",
        "            args.output_dir = ['./output/']\n",
        "            args.train_dir = ['./data/train/']\n",
        "            args.val_dir = ['./data/validation/']\n",
        "            args.epoch = [10]\n",
        "            args.batch = [4]\n",
        "            args.train_model = [True]\n",
        "            args.load_weights = [False]\n",
        "            args.load_checkpoint = [False]\n",
        "            args.fine_tune = [True]\n",
        "            args.test_aug = [False]\n",
        "            args.train_aug = [False]\n",
        "            args.plot = [False]\n",
        "            args.model_summary = [False]\n",
        "            args.dropout = [0.6]\n",
        "            args.learning_rate = [1e-8]\n",
        "            args.decay = [0.0]\n",
        "            args.optimizer_val = ['rms'] # 'rms', 'sgd', 'ada'\n",
        "            args.frozen_layers = [150]\n",
        "            args.base_model = ['inceptionv4']\n",
        "            args.saved_chkpnt\n",
        "    :return: Null\n",
        "    \"\"\"\n",
        "\n",
        "    # Get output dir ##########################################################\n",
        "    if not os.path.exists(args.output_dir[0]):\n",
        "        os.makedirs(args.output_dir[0])\n",
        "\n",
        "    # Get optimizer, learning rate, decay parameters ##########################\n",
        "    optimizer_val = args.optimizer_val[0]\n",
        "    lr = args.learning_rate[0]\n",
        "    decay = args.decay[0]\n",
        "\n",
        "    # Set optimizer based on user input #######################################\n",
        "    if optimizer_val.lower() == 'sgd':\n",
        "        optimizer = SGD(lr=lr, decay=decay, momentum=1, nesterov=True)\n",
        "        print(\"Using SGD as the optimizer ...\")\n",
        "    elif optimizer_val.lower() == 'rms' or optimizer_val.lower() == 'rmsprop':\n",
        "        optimizer = RMSprop(lr=lr, rho=0.9, epsilon=1e-08, decay=decay)\n",
        "        print(\"Using RMSProp as the optimizer ...\")\n",
        "    elif optimizer_val.lower() == 'ada':\n",
        "        optimizer = Adagrad(lr=lr, epsilon=1e-08, decay=decay)\n",
        "        print(\"Using Adagrad as the optimizer ...\")\n",
        "    else:\n",
        "        optimizer = DEFAULT_OPTIMIZER\n",
        "\n",
        "    # Get number training samples and classes #################################\n",
        "    nb_train_samples = get_nb_files(args.train_dir[0])\n",
        "    nb_classes = len(glob.glob(args.train_dir[0] + \"/*\"))\n",
        "    print(\"Total number of training samples = \" + str(nb_train_samples))\n",
        "    print(\"Number of training classes = \" + str(nb_classes))\n",
        "\n",
        "    # Get number validation samples and classes ###############################\n",
        "    nb_val_samples = get_nb_files(args.val_dir[0])\n",
        "    nb_val_classes = len(glob.glob(args.val_dir[0] + \"/*\"))\n",
        "    print(\"Total number of validation samples = \" + str(nb_val_samples))\n",
        "    print(\"Number of validation classes = \" + str(nb_val_classes))\n",
        "\n",
        "    # START TRAINING if train labels == valid labels ##########################\n",
        "    if nb_val_classes == nb_classes:\n",
        "        print(\"Initiating training session ...\")\n",
        "    else:\n",
        "        print(\"Mismatched number of training and validation data classes ...\")\n",
        "        print(\"Unequal number of sub-folders found between train and \"\n",
        "              \"validation directories ...\")\n",
        "        print(\"Each sub-folder in train and validation directroies are \"\n",
        "              \"treated as a separate class ...\")\n",
        "        print(\"Correct this mismatch and re-run ...\")\n",
        "        print(\"Now exiting ...\")\n",
        "        sys.exit(1)\n",
        "\n",
        "    # Get num epochs, batch size, train aug ###################################\n",
        "    nb_epoch = int(args.epoch[0])\n",
        "    batch_size = int(args.batch[0])\n",
        "    train_aug = args.train_aug[0]\n",
        "\n",
        "    # Grab Base Model to train op top of  [TRANSF LEARNING] ###################\n",
        "    if str((args.base_model[0]).lower()) == 'inceptionv4' or \\\n",
        "                    str((args.base_model[0]).lower()) == 'inception_v4' or \\\n",
        "                    str((args.base_model[0]).lower()) == 'inception_resnet':\n",
        "        preprocess_input = preprocess_input_inceptionv4\n",
        "    else:\n",
        "        preprocess_input = preprocess_input_inceptionv3\n",
        "\n",
        "    # ?????? ##################################################################\n",
        "    if train_aug == True:\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    else:\n",
        "        train_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input)\n",
        "\n",
        "    # ?????? ##################################################################\n",
        "    test_aug = args.test_aug[0]\n",
        "    if test_aug == True:\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input,\n",
        "            rotation_range=30,\n",
        "            width_shift_range=0.2,\n",
        "            height_shift_range=0.2,\n",
        "            shear_range=0.2,\n",
        "            zoom_range=0.2,\n",
        "            horizontal_flip=True)\n",
        "    else:\n",
        "        test_datagen = ImageDataGenerator(\n",
        "            preprocessing_function=preprocess_input)\n",
        "\n",
        "    # Getting training data ###################################################\n",
        "    print(\"Generating training data: ... \")\n",
        "    train_generator = train_datagen.flow_from_directory(args.train_dir[0],\n",
        "                                                        target_size=(\n",
        "                                                        IM_WIDTH, IM_HEIGHT),\n",
        "                                                        batch_size=batch_size,\n",
        "                                                        class_mode='categorical')\n",
        "\n",
        "    # Getting validation data #################################################\n",
        "    print(\"Generating validation data: ... \")\n",
        "    validation_generator = test_datagen.flow_from_directory(args.val_dir[0],\n",
        "                                                            target_size=(\n",
        "                                                            IM_WIDTH,\n",
        "                                                            IM_HEIGHT),\n",
        "                                                            batch_size=batch_size,\n",
        "                                                            class_mode='categorical')\n",
        "\n",
        "    # If base model an inception net ##########################################\n",
        "    if str((args.base_model[0]).lower()) == 'inceptionv4' or\\\n",
        "        str((args.base_model[0]).lower()) == 'inception_v4' or\\\n",
        "        str((args.base_model[0]).lower()) == 'inception_resnet':\n",
        "        base_model = InceptionResNetV2(weights='imagenet', \\\n",
        "                                       include_top=False)\n",
        "        base_model_name = 'Inception version 4'\n",
        "    else:\n",
        "        # Model argument: include_top=False excludes the final FC layer\n",
        "        base_model = InceptionV3(weights='imagenet',\n",
        "                                 include_top=False)\n",
        "        base_model_name = 'Inception version 3'\n",
        "    print('Base model: ' + str(base_model_name))\n",
        "\n",
        "    # Add a new layer to the base model #######################################\n",
        "    model = add_top_layer(base_model, nb_classes)\n",
        "    print(\"New top layer added to: \" + str(base_model_name))\n",
        "\n",
        "    # get classification labels, if to load checkpoints, previous weights,etc #\n",
        "    labels = generate_labels(args)\n",
        "    load_weights_ = args.load_weights[0]\n",
        "    fine_tune_model = args.fine_tune[0]\n",
        "    load_checkpoint = args.load_checkpoint[0]\n",
        "    checkpointer_savepath = os.path.join(args.output_dir[0] +\n",
        "                                         '/checkpoint/Transfer_learn_' +\n",
        "                                         str(IM_WIDTH) + '_' +\n",
        "                                         str(IM_HEIGHT) + '_' + '.h5')\n",
        "\n",
        "    # Getting previous weights from checkpoint, else new model ################\n",
        "    if load_weights_ == True and load_checkpoint == False:\n",
        "        try:\n",
        "            with open(args.config_file[0]) as json_file:\n",
        "                model_json = json_file.read()\n",
        "            model = model_from_json(model_json)\n",
        "        except:\n",
        "            model = model\n",
        "        try:\n",
        "            model.load_weights(args.weights_file[0])\n",
        "            print(\"Loaded model weights from: \" + str(args.weights_file[0]))\n",
        "        except:\n",
        "            print(\"Error loading model weights ...\")\n",
        "            print(\"Loaded default model weights ...\")\n",
        "    elif load_checkpoint == True:\n",
        "        try:\n",
        "            model = load_model(checkpointer_savepath)\n",
        "            print(\n",
        "                \"Loaded model from checkpoint: \" + str(checkpointer_savepath))\n",
        "        except:\n",
        "            if os.path.exists(args.saved_chkpnt[0]):\n",
        "                model = load_model(args.saved_chkpnt[0])\n",
        "                print('Loaded saved checkpoint file ...')\n",
        "            else:\n",
        "                print(\"Error loading model checkpoint ...\")\n",
        "                print(\"Loaded default model weights ...\")\n",
        "    else:\n",
        "        model = model\n",
        "        print(\"Tabula rasa ...\")\n",
        "\n",
        "    # Checking and freezing certain layers during training ####################\n",
        "    try:\n",
        "        NB_FROZEN_LAYERS = args.frozen_layers[0]\n",
        "    except:\n",
        "        NB_FROZEN_LAYERS = DEFAULT_NB_LAYERS_TO_FREEZE\n",
        "    if fine_tune_model == True:\n",
        "        print(\"Fine tuning Inception architecture ...\")\n",
        "        print(\"Frozen layers: \" + str(NB_FROZEN_LAYERS))\n",
        "        setup_to_finetune(model, optimizer, NB_FROZEN_LAYERS)\n",
        "    else:\n",
        "        print(\"Transfer learning using Inception architecture ...\")\n",
        "        setup_to_transfer_learn(model, base_model, optimizer)\n",
        "\n",
        "    # START TRAINING ##########################################################\n",
        "    print(\"Initializing training with  class labels: \" + str(labels))\n",
        "\n",
        "    # checking and printing current model summary prior to training\n",
        "    model_summary_ = args.model_summary[0]\n",
        "    if model_summary_ == True:\n",
        "        print(model.summary())\n",
        "    else:\n",
        "        print(\n",
        "            \"Successfully loaded deep neural network classifier for training \")\n",
        "\n",
        "    # getting checkpoint file prepared\n",
        "    if not os.path.exists(os.path.join(args.output_dir[0] + '/checkpoint/')):\n",
        "        os.makedirs(os.path.join(args.output_dir[0] + '/checkpoint/'))\n",
        "\n",
        "    # setting up checkpoint, learning rate\n",
        "    earlystopper = EarlyStopping(patience=6, verbose=1)\n",
        "    checkpointer = ModelCheckpoint(checkpointer_savepath,\n",
        "                                   verbose=1,\n",
        "                                   save_best_only=True)\n",
        "    learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n",
        "                                                patience=2,\n",
        "                                                mode='min',\n",
        "                                                epsilon=1e-4,\n",
        "                                                cooldown=1,\n",
        "                                                verbose=1,\n",
        "                                                factor=0.5,\n",
        "                                                min_lr=lr * 1e-2)\n",
        "\n",
        "    # training command\n",
        "    model_train = model.fit_generator(train_generator,\n",
        "                                      epochs=nb_epoch,\n",
        "                                      steps_per_epoch=2000,\n",
        "                                      validation_data=validation_generator,\n",
        "                                      validation_steps=2000,\n",
        "                                      class_weight='auto',\n",
        "                                      callbacks=[earlystopper,\n",
        "                                                 learning_rate_reduction,\n",
        "                                                 checkpointer])\n",
        "\n",
        "    # saving model and training plots\n",
        "    if fine_tune_model == True:\n",
        "        save_model(args, \"_ft_\", model)\n",
        "        generate_plot(args, \"_ft_\", model_train)\n",
        "    else:\n",
        "        save_model(args, \"_tl_\", model)\n",
        "        generate_plot(args, \"_tl_\", model_train)\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "########################### DEFAULT PARAMETERS ################################\n",
        "\n",
        "IM_WIDTH, IM_HEIGHT = 299, 299  # Fixed input image size for Inception\n",
        "DEFAULT_EPOCHS = 100\n",
        "DEFAULT_BATCHES = 20\n",
        "FC_SIZE = 4096\n",
        "DEFAULT_DROPOUT = 0.1\n",
        "DEFAULT_NB_LAYERS_TO_FREEZE = 169\n",
        "\n",
        "sgd = SGD(lr=1e-7, decay=0.5, momentum=1, nesterov=True)\n",
        "rms = RMSprop(lr=1e-7, rho=0.9, epsilon=1e-08, decay=0.0)\n",
        "ada = Adagrad(lr=1e-3, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "DEFAULT_OPTIMIZER = ada\n",
        "timestr = generate_timestamp()\n",
        "###############################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exHK7SQjtqhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import types\n",
        "\n",
        "model_dir = \"./drive/EFIGI_Galaxy_Classification/model/\"\n",
        "output_dir = \"./drive/EFIGI_Galaxy_Classification/output/\"\n",
        "checkpoint_dir = \"./drive/EFIGI_Galaxy_Classification/output/checkpoint/\"\n",
        "\n",
        "\n",
        "args = types.SimpleNamespace()\n",
        "args.config_file = [model_dir+'model_efc.json']\n",
        "args.output_dir = [output_dir]\n",
        "args.train_dir = ['./data/train/']\n",
        "args.val_dir = ['./data/validation/']\n",
        "args.epoch = [100]# at least 100 epochs\n",
        "args.batch = [60]\n",
        "args.train_model = [True]\n",
        "args.load_weights = [False]\n",
        "args.load_checkpoint = [True] # Set it to true for using a saved checkpoint\n",
        "args.fine_tune = [True]\n",
        "args.test_aug = [False]\n",
        "args.train_aug = [False]\n",
        "args.plot = [True]\n",
        "args.model_summary = [False]\n",
        "args.dropout = [0.95]\n",
        "args.learning_rate = [1e-3]\n",
        "args.decay = [0.0]\n",
        "args.optimizer_val = ['adam'] # 'rms', 'sgd', 'ada'\n",
        "args.frozen_layers = [140]\n",
        "args.base_model = ['inceptionv4']\n",
        "args.saved_chkpnt = [checkpoint_dir+'transfer_learn_299_299_.h5']\n",
        "args.activation = ['elu']\n",
        "\n",
        "\n",
        "def ensure_dir(file_path):\n",
        "    directory = os.path.dirname(file_path)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "ensure_dir(model_dir)\n",
        "ensure_dir(output_dir)\n",
        "ensure_dir(checkpoint_dir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL_tT3buttew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_model = args.train_model[0]\n",
        "    \n",
        "if train_model ==True:\n",
        "  print (\"Training sesssion initiated ...\")\n",
        "  train(args)\n",
        "else:\n",
        "  print (\"Nothing to do here ...\")\n",
        "  print (\"Try setting the --train_model flag to True ...\")\n",
        "  print (\"For more help, run with -h flag ...\")\n",
        "  sys.exit(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FyWbJoGGbqz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mv ./drive/EFIGI_Galaxy_Classification/output//checkpoint/Transfer_learn_299_299_.h5 /content/gdrive/My\\ Drive/Transfer_learn_299_299_EFIGI.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UY8IL-JMEsKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}